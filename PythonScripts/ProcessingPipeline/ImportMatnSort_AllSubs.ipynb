{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "import mne\n",
    "from mne.viz import plot_topomap\n",
    "from mne.viz import set_3d_title, set_3d_view\n",
    "sns.set_theme() # set the plotting atmosphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all files that will be sorted and exported into another .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files Avilable: 50\n",
      "Current WD: C:\\plimon\\LTP_analysis\\eegMatFiles\\MAT\\nl-2697_attnL_20231120_1601_RLS.mat\n",
      "Does File #1 Exist? True\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "#MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AvgCRFs\\\\' # set dir\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegMatFiles\\\\MAT' # set dir\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "dataFileNames = os.listdir(MainDir) # list files in dir\n",
    "print(f'Total Files Avilable: {len(dataFileNames)}')\n",
    "##############################################\n",
    "FileN = dataFileNames[34]# choose one                        \n",
    "file_path1 = os.path.join(MainDir, FileN) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove # to import all files and then just use this (saves compu time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # small script to import data + filenames for 1 condition \n",
    "# SignalDataDict={} # fill with subjects signal data\n",
    "# FileNamesIndicies = []\n",
    "# for Fname in range(len(dataFileNames)):\n",
    "#     dataFileIn = dataFileNames[Fname]\n",
    "#     filePath =  os.path.join(MainDir, dataFileIn) # join paths and prep 2 load\n",
    "#     mat_data = scipy.io.loadmat(filePath) # import data file\n",
    "#     MainData = mat_data['signalData'][0][0] # condition and \n",
    "#     #print(MainData.shape)\n",
    "#     SignalDataDict[Fname] = MainData\n",
    "#     FileNamesIndicies.append(dataFileIn)\n",
    "    \n",
    "# FileNamesIndicies = np.array(FileNamesIndicies) # make list into array \n",
    "# FileName = [FileNamesIndicies.replace('_','-') for FileNamesIndicies in FileNamesIndicies] # uniform fnames to make bools for attnl and attnR \n",
    "# DataOut = {}\n",
    "\n",
    "# DataOut['RawData'] = SignalDataDict\n",
    "# DataOut['SubjNames'] = FileName\n",
    "# SaveDataDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegMatFiles\\\\AllMat'\n",
    "# print(os.path.exists(SaveDataDir)) # does pth exist :p\n",
    "\n",
    "# dnt = datetime.now() # add date and time bc im wreckless when saving ..\n",
    "# fdnt = dnt.strftime(\"%Y%m%d_%H%M%S\") # set the above as a string ...\n",
    "# FileOutName = 'AllSubj_MatFiles_C1'\n",
    "# FileN = f'{FileOutName}_{fdnt}.pkl' \n",
    "# NewFileNPath = os.path.join(SaveDataDir,FileN)\n",
    "# print('Full New File Dir: ', NewFileNPath)\n",
    "\n",
    "# saveFile = 'y'\n",
    "# if saveFile == 'y':\n",
    "#  with open(NewFileNPath, 'wb') as file:\n",
    "#     pkl.dump(DataOut, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "#     print('MAT Data For All Subjs Saved! :))')\n",
    "# else:\n",
    "#     print('Did Not Save File! Change file name before switching to y!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Keys in original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'info', 'signalData', 'noise1', 'noise2'])\n"
     ]
    }
   ],
   "source": [
    "mat_data = scipy.io.loadmat(file_path1) # import data file\n",
    "print((mat_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index certain keys for analysis and conditions during expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file contains data for 6 different conditions\n"
     ]
    }
   ],
   "source": [
    "# find basic data parms \n",
    "MainData = mat_data['signalData']\n",
    "noise1 = mat_data['noise1'] # 6 x 1 \n",
    "noise2 = mat_data['noise2']\n",
    "inds = mat_data['info'][0][0]\n",
    "ExpConds = int(MainData.shape[0])\n",
    "print(f'Data file contains data for {ExpConds} different conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Channels of Interest to Visualize Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels to be visualized: [ 30  36  40  41  44  45  46  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98 100 101 102 106 107 112]\n"
     ]
    }
   ],
   "source": [
    "elecLeftLateral=[51,52,60,58,59,64,65,68,69]\n",
    "elecLeftMedial=[72,75,81,70,71,74]\n",
    "elecRightMedial=[72,75,81,76,83,82]\n",
    "elecMedial=[72,75,81,70,71,74,76,83,82]\n",
    "elecRightLateral=[97,92,85,96,91,95,90,94,88]\n",
    "extraChans = np.arange(50,100,1) #\n",
    "extra = [107,101,47,42,37,31,102,46,41,45,49,103,108,113,108,99]\n",
    "\n",
    "AnalysisChans = [elecLeftLateral,elecLeftMedial,elecRightMedial,elecMedial,elecRightLateral,extraChans,extra]\n",
    "ExportChans = np.unique(np.sort(np.concatenate(AnalysisChans))) # Combine array for chans of interest\n",
    "ExportChans  = ExportChans - 1\n",
    "\n",
    "# ExportChans = [71,74]\n",
    "print(f'Channels to be visualized: {ExportChans}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Condition Data, Noise 1 and Noise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save signal data\n",
    "FreqDataPerCo = {}\n",
    "for co in range(ExpConds):\n",
    "    #print(MainData[co][0].shape)\n",
    "    FreqDataPerCo[co] = MainData[co][0]\n",
    "# noise data 1 \n",
    "Noise1DataPerCo = {}\n",
    "for co in range(ExpConds):\n",
    "    #print(noise1[co][0].shape)\n",
    "    Noise1DataPerCo[co] = noise1[co][0]\n",
    "# noise data 2\n",
    "Noise2DataPerCo = {}\n",
    "for co in range(ExpConds):\n",
    "    #print(noise2[co][0].shape)\n",
    "    Noise2DataPerCo[co] = noise2[co][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicies To Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = 0 # pre and post induction ltp\n",
    "HarmInd = np.ravel(mat_data['info'][0][0] [0][co][0])\n",
    "BinInd = np.ravel(mat_data['info'][0][0] [1][co][0])\n",
    "#HarmonLabels = mat_data['info'][0][0][2][co][0]\n",
    "AvgAct = mat_data['info'][0][0] [3][co] [0] # returns an array with 6 values ...\n",
    "NumCondInd = mat_data['info'][0][0][4][co][0] # bin index, includes preludes\n",
    "HemiFieldLabels = mat_data['info'][0][0] [2][co][0] # contains harmonic and hemifield data\n",
    "hemiFieldnHarmonicInd = mat_data['info'][0][0] [2][co] [0]\n",
    "#########In case some nested arrays need to be extracted or explored\n",
    "# co = 0\n",
    "# ind = 2\n",
    "# inds = mat_data['info'][0][0] [ind][co] [0] # avoid prelude bind which == 0 actually \n",
    "# #print(inds)\n",
    "# for innerlist in inds:\n",
    "#     for item in innerlist:\n",
    "#        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get and Set Boundaries for Data Sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamronics:  (array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([7, 7, 7, 7, 7, 7, 7, 7, 7], dtype=int64))\n",
      "Bin Indicies:  (array([0, 1, 2, 3, 4, 5, 6], dtype=uint8), array([9, 9, 9, 9, 9, 9, 9], dtype=int64))\n",
      "Total Bins #6\n"
     ]
    }
   ],
   "source": [
    "NumHarms,NumHarmCount = np.unique(HarmInd, return_counts = True)\n",
    "print(f'Hamronics:  {NumHarms,NumHarmCount}')\n",
    "NumBins,NumBinCount = np.unique(BinInd, return_counts = True)\n",
    "print(f'Bin Indicies:  {NumBins,NumBinCount}')\n",
    "Bins = int(len(NumBins)-1)\n",
    "print(f'Total Bins #{Bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SortDataIn =  FreqDataPerCo[0] # 112 x 128 x 78\n",
    "[NumRows, NumChans, NumTrials] = SortDataIn.shape # get dims of data to use later ..\n",
    "print(f'DataVals, Channels , Total Trials: {SortDataIn.shape}')\n",
    "real_imag_bound = int((NumRows/2))\n",
    "print(f'Data real-imag bound is at row: #{real_imag_bound}')\n",
    "chanInd = np.arange(0,NumChans,1)\n",
    "print(f'total channels: {chanInd.shape}')\n",
    "prepost_bound = int(NumTrials/2)\n",
    "HemiBound = int(int(len(HemiFieldLabels))/2)\n",
    "print(f'Data will be split at the 4th row when called for hemifield segmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Bool mask for MNE Topoplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocm = np.zeros((NumChans), dtype = bool) # mask of len nchans\n",
    "ocm[ExportChans] = True # set good chans to true "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Real and Imaginary Components of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data into real and imaginary data side by side\n",
    "dIn = FreqDataPerCo[co].reshape(real_imag_bound,2,NumChans,NumTrials) # 56 x 2 x 128 x 78\n",
    "n1 = Noise1DataPerCo[co].reshape(real_imag_bound,2,NumChans,NumTrials)\n",
    "n2 = Noise2DataPerCo[co].reshape(real_imag_bound,2,NumChans,NumTrials)\n",
    "# Clean Data\n",
    "# remove 0s -> nans\n",
    "dIn[dIn == 0] = np.nan\n",
    "n1[n1 == 0] = np.nan\n",
    "n2[n2 == 0] = np.nan\n",
    "# empty dataframes\n",
    "DataOut = np.zeros((real_imag_bound,NumChans,NumTrials))\n",
    "n1Out = np.zeros_like(DataOut)\n",
    "n2Out = np.zeros_like(DataOut)\n",
    "# combine real and imaginary compnents for signal data, noise 1 and noise 2 \n",
    "for val in range(real_imag_bound):\n",
    "    DataOut[val,:,:] = np.hypot(dIn[val,0,:,:],dIn[val,1,:,:]) # (56,128, 78)\n",
    "    n1Out[val,:,:] = np.hypot(n1[val,0,:,:],n1[val,1,:,:]) # (56, 128, 78)\n",
    "    n2Out[val,:,:] = np.hypot(n2[val,0,:,:],n2[val,1,:,:]) # (56, 128, 78)\n",
    "print(DataOut.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data Per Bin and Store in Dict, Remove Prelude Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPerBin = {}\n",
    "for i in range(len(NumBins)):\n",
    "    if i > 0:\n",
    "        bin_arr = np.zeros_like((BinInd))\n",
    "        bin_arr[BinInd == i] = 1 # changr bool ind to get bin specific data\n",
    "        dataPerBin[i-1] = DataOut[bin_arr == 1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Point #1** : Make sure 1F1 harmonic data is **NOT** included in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colDim = np.shape(dataPerBin[0])[0]\n",
    "\n",
    "if colDim != (HemiBound*2):\n",
    "    temp_dataPerBin = {} # write over original data in temp\n",
    "\n",
    "    print(f'1F1 data is included, now removing this data...')\n",
    "\n",
    "    for i in range(int(len(NumBins))-1):\n",
    "        dOut = dataPerBin[i][1:,:,:]\n",
    "        print(f'Data out dims: {dOut.shape}')\n",
    "        temp_dataPerBin[i] = dOut\n",
    "        print(f'All Done! :)')\n",
    "    print(f'Data shapes are now good!')\n",
    "    \n",
    "    dataPerBin = temp_dataPerBin # rewrite over old data\n",
    "\n",
    "else:\n",
    "    print(f'Data is correct dims!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 and F2 data are stacked on top of each other so here we split them :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF1Bins = {} # data is : 2f1 4f1 6f1 8f1\n",
    "xF2Bins = {} # data is  2f2 4f2 6f2 8f2\n",
    "\n",
    "for i in range(Bins):\n",
    "    data2split = dataPerBin[i] # 8 x 128 x 78\n",
    "    xF1Bins[i] = np.array(data2split[:HemiBound,:,:]) # harmonics x channels x trials  = 4 x 128 x 78\n",
    "    xF2Bins[i] = np.array(data2split[HemiBound:,:,:]) # harmonics x channels x trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickBin = 0\n",
    "pickTrial = 60\n",
    "print(f'Channel activity per trial: harmonic, bin and hemifield')\n",
    "ch_list = np.arange(0,NumChans,1)\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF1Bins[pickBin][i,:,pickTrial], label = f'{(i+1)*2}F1') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF2Bins[pickBin][i,:,pickTrial], label = f'{(i+1)*2}F2') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperate data into pre and post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepost_bound= int(NumTrials/2) # reshape will occure at this ind \n",
    "\n",
    "xF1_pre_post = {} # F1 pre post data\n",
    "xF2_pre_post = {} # F2 pre post data\n",
    "\n",
    "for i in range(Bins):\n",
    "    xF1_pre_post[i] = np.reshape(xF1Bins[i], newshape = (4,NumChans,prepost_bound,2))\n",
    "    xF2_pre_post[i] = np.reshape(xF2Bins[i], newshape = (4,NumChans,prepost_bound,2)) # 4 x 128 x pre / post trials  x 2# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize data not for analysis - data is not comperable but more to make sure there is variance between trials, hemifields and harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickBin = 0\n",
    "pickTrial = 9\n",
    "print(f'channel activity per trial: harmonic, bin and hemifield')\n",
    "ch_list = np.arange(0,NumChans,1)\n",
    "\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF1_pre_post[pickBin][i,:,pickTrial,0], label = f'{(i+1)*2}F1 pre') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF1_pre_post[pickBin][i,:,pickTrial,1], label = f'{(i+1)*2}F1 post') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF2_pre_post[pickBin][i,:,pickTrial,0], label = f'{(i+1)*2}F2 pre') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF2_pre_post[pickBin][i,:,pickTrial,1], label = f'{(i+1)*2}F2 post') # plot per channel actiivity \n",
    "    plt.vlines(40, ymin = 0 , ymax = 3, color = 'black')\n",
    "    plt.vlines(100, ymin = 0, ymax = 3, color = 'black')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concate Data Across Bins to Get Average Activity Per Channel, Bin and Harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF1_CleanAvgs = {}\n",
    "xF2_CleanAvgs = {}\n",
    "\n",
    "for prepost in range(2):\n",
    "    xF1_CleanAvgs[prepost] = {} # make a new dict key for pre and then post \n",
    "    xF2_CleanAvgs[prepost] = {}\n",
    "    for bin in range(Bins):\n",
    "        #enter data dict\n",
    "        xF1_dIn = xF1_pre_post[bin] # 4  x 128 x ntrials x pre / post\n",
    "        xF2_dIn = xF2_pre_post[bin]\n",
    "        # avg harmonic activity per channel\n",
    "        xF1_CleanAvgs[prepost][bin] = np.nanmean(xF1_dIn[:,:,:,prepost],axis = -1) # average data per trial to get 1 val per channel\n",
    "        xF2_CleanAvgs[prepost][bin] = np.nanmean(xF2_dIn[:,:,:,prepost],axis = -1) # average data per trial to get 1 val per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepo = ['pre', 'post']\n",
    "\n",
    "binInd = 5\n",
    "fig, axs = plt.subplots(1,2,figsize = (10,5),sharey = True)\n",
    "for prepost in range(2):\n",
    "    dIn = xF1_CleanAvgs[prepost]\n",
    "    for hi in range(4):\n",
    "        axs[prepost].scatter(ch_list,dIn[binInd][hi,:], label = f'{(hi+1)*2}F1 {pepo[prepost]}')\n",
    "        axs[prepost].hlines(0,xmin = 0,xmax = 128, color = 'black')\n",
    "    plt.suptitle('XF1 average channel activity per bin')\n",
    "    axs[prepost].legend()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize = (10,5),sharey = True)\n",
    "for prepost in range(2):\n",
    "    dIn = xF2_CleanAvgs[prepost]\n",
    "    for hi in range(4):\n",
    "        axs[prepost].scatter(ch_list,dIn[binInd][hi,:], label = f'{(hi+1)*2}F2 {pepo[prepost]}')\n",
    "        axs[prepost].hlines(0,xmin = 0,xmax = 128, color = 'black')\n",
    "    plt.suptitle('XF2 average channel activity per bin')\n",
    "    axs[prepost].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Data Across Harmonics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XF1_Data = {}\n",
    "XF2_Data = {}\n",
    "\n",
    "for prepost in range(2):\n",
    "    \n",
    "    XF1_Data[prepost] = {}\n",
    "    XF2_Data[prepost] = {}\n",
    "    temp_XF1 = np.concatenate([xF1_CleanAvgs[prepost][x] for x in xF1_CleanAvgs[prepost]])\n",
    "    temp_XF2 = np.concatenate([xF2_CleanAvgs[prepost][x] for x in xF2_CleanAvgs[prepost]])\n",
    "    XF1_Data[prepost] = np.reshape(temp_XF1, newshape = (4,Bins,NumChans))\n",
    "    XF2_Data[prepost] = np.reshape(temp_XF2, newshape =(4,Bins,NumChans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2, figsize = (12,6), sharey = True)\n",
    "plt.suptitle('Pre  + Post Channel Activity XF2')\n",
    "for pltpos in range(2):\n",
    "    pepo = XF2_Data[pltpos] # plot pre and post data\n",
    "    for i in range(Bins):\n",
    "        harmtwo  = pepo[0,i,:]\n",
    "        ht = np.nanmean(harmtwo,axis = 0) # 128 points of avg channel activity pre or post \n",
    "        axs[pltpos].scatter(ch_list,harmtwo, label = f'Bin: {i}')\n",
    "        axs[pltpos].legend()\n",
    "# plt.title(f'activity per channel across all bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Difference in Response Activity Post - Pre Induction\n",
    "## Method # 1: Post - Pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF1 Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_temp_pre = XF1_Data[0] # 4 x 6 x 128\n",
    "f1_temp_post = XF1_Data[1] # 4 x 6 x 128\n",
    "\n",
    "XF1_diffs = np.zeros_like((f1_temp_pre)) # temporary store of data \n",
    "\n",
    "for hi in range(4):\n",
    "    for bin in range(Bins):\n",
    "        diff = (f1_temp_post[hi,bin,:] - f1_temp_pre[hi,bin,:])\n",
    "        XF1_diffs[hi,bin,:] = diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_temp_pre = XF2_Data[0] # 4 x 6 x 128\n",
    "f2_temp_post = XF2_Data[1] # 4 x 6 x 128\n",
    "\n",
    "XF2_diffs = np.zeros_like((f2_temp_pre)) # temporary store of data \n",
    "\n",
    "for hi in range(4):\n",
    "    for bin in range(Bins):\n",
    "        diff = (f2_temp_post[hi,bin,:] - f2_temp_pre[hi,bin,:])\n",
    "        XF2_diffs[hi,bin,:] = diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Checkpoint #2** Before Plotting Topos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.sum(XF1_diffs == XF2_diffs) == 0:\n",
    "    print(f'Data does not overlap, good sign') # check if data is the same\n",
    "else:\n",
    "    print(f'check data indcies as data is the same for both hemifields')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Harmonic Data to Visualize, transpose data and Add Dead Channel for Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Harmonic = 0 # pick harmoic data to plot on topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF1 Difference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_Diffs = XF1_diffs[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "print(F1_Diffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF2 Difference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2_Diffs = XF2_diffs[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "print(F2_Diffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select EEG Montage for MNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set EEG Sensor Location File and Set as Default Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eegMontageDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegSensorLocs\\\\9_18AverageNet128_v1.sfp'#AdultAverageNet128_v1.sfp'\n",
    "# # Check if the file exists\n",
    "# if os.path.exists(eegMontageDir):\n",
    "#     # Load the electrode locations file\n",
    "#     montageIn = mne.channels.read_custom_montage(eegMontageDir) # import file\n",
    "#     print(\"Electrode locations loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"The specified file does not exist.\")\n",
    "# print(montageIn)\n",
    "# #### Get channel names to use\n",
    "# info = mne.create_info(ch_names=montageIn.ch_names, sfreq=1, ch_types=\"eeg\")\n",
    "# info.set_montage(montageIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montageIn = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "info = mne.create_info(ch_names=montageIn.ch_names, sfreq=1, ch_types=\"eeg\")\n",
    "info.set_montage(montageIn)\n",
    "print(montageIn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF1_Data[0]\n",
    "data = p[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 10),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f' Pre F1 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i] # plot data per bin\n",
    "    # hashtag below to plot all channel activity\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 4)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF1_Data[1]\n",
    "data = p[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Post F1 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot F1 Difference post induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'F1 response change post induction, Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = F1_Diffs[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ploting F2 Data Now, 2nd harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF2_Data[0]\n",
    "\n",
    "data = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Pre F2 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i] # 129 array\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF2_Data[1]\n",
    "data = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Post F2 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 4)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Bins):\n",
    "    #plt.plot(topodata[:,i])\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'F2 response change post induction, Bin # {i+1}', fontsize = 30)\n",
    "    #placeholder = np.random.random((10, 10))\n",
    "    #axs.imshow(placeholder)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = F2_Diffs[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topodata = p[0,:,:].T\n",
    "# print(topodata.shape)\n",
    "# emptyChData = np.zeros((1,6))\n",
    "# print(emptyChData.shape)\n",
    "\n",
    "# dataFull = np.array(np.concatenate((topodata,emptyChData)))\n",
    "\n",
    "# data = dataFull[:,4]\n",
    "\n",
    "# # create array with 4 points for our 4 channels\n",
    "# # in the same order as provided in ch_names\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10),gridspec_kw=dict(height_ratios=[3]))\n",
    "# axes.set_title(f'subj topo plot', fontsize = 30)\n",
    "# # placeholder = np.random.random((10, 10))\n",
    "# # axes.imshow(placeholder)\n",
    "# axes.axis('off')\n",
    "\n",
    "# #info = create_info(ch_names=montageIn._names, sfreq=1, ch_types='eeg')\n",
    "# # channel names I provided are part of a standard montage\n",
    "# #info.set_montage(montageIn) # import file)\n",
    "# im,_ = plot_topomap(data, info, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 8)\n",
    "# divider = make_axes_locatable(axes)\n",
    "# cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "# cbar = plt.colorbar(im, cax=cax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good confined example of what data formate is supposed to look like for mne plotting success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne import create_info\n",
    "# from mne.viz import plot_topomap\n",
    "# import numpy as np\n",
    "\n",
    "# # create array with 4 points for our 4 channels\n",
    "# # in the same order as provided in ch_names\n",
    "# data = np.random.randn(4)  \n",
    "# info = create_info(ch_names=['CPz', 'Oz', 'POz', 'Fz'], sfreq=1000, ch_types='eeg')\n",
    "# # channel names I provided are part of a standard montage\n",
    "# info.set_montage('standard_1020')\n",
    "\n",
    "# plot_topomap(data, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topodata = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "# #have to add some fck channel data because egi file included one extra channel\n",
    "# emptyChData = np.zeros((1,6)) # 1 x 6\n",
    "# data = np.array(np.concatenate((topodata,emptyChData))) # 129 x 6 \n",
    "\n",
    "\n",
    "# for i in range(6):\n",
    "#     #plt.plot(topodata[:,i])\n",
    "#     fig, axs = plt.subplots(figsize = (6,6))\n",
    "#     axs.set_title(f'Bin # {i}')\n",
    "#     axs.legend()\n",
    "#     print(i)\n",
    "#     dataIn = data[:,i]\n",
    "#     mne.viz.plot_topomap(dataIn, info, axes = axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot formats of the past and present(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (10,10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# montageIn.plot(kind='3d', axes=ax)\n",
    "# ax.set_title('Sensor Locations')\n",
    "# plt.show()\n",
    "# # Plot the sensors on a 2D head model\n",
    "# fig, ax = plt.subplots()\n",
    "# montageIn.plot(kind='topomap', show_names=True, axes=ax)\n",
    "# ax.set_title('Sensor Locations (2D)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #montge default info in case egi outut file fails me \n",
    "# montage_type = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "# print(montage_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_label = ['2F','4F','6F','8F']\n",
    "\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF1_Data[0][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Pre F1 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "#plt.show()\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF1_Data[1][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Post F1 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF2_Data[0][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Pre F2 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF2_Data[1][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Post F2 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
