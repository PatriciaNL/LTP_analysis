{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP TWO** OF PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script imports all data that we sorted in step one and visualizes the data for each participant. ideally, this script and its plots should be used to perform visual inspection and start determining is some data was too noisy to be included. This script exports average contrast response functions for each participant.\n",
    "\n",
    "### Upcoming goals 2/27/24: check if no saturation can be plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy.io\n",
    "from scipy.io   import  loadmat\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from scipy.optimize import curve_fit \n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanRCA(x): # replace 0's in data with nan's\n",
    "    x[x == 0] = np.nan\n",
    "    return x\n",
    "################################################################################\n",
    "# comine real and imaginary numbers, only 1st component - For average across pre and post\n",
    "def CombineRealImg(x, NumHarms):\n",
    "    [NumCols, NumTrials] = np.shape(x) # 24 x 78-80\n",
    "    DomainCutoff = int(NumCols/NumHarms) # use to index cutoff  - float -> int\n",
    "    CondCutoff = int(NumTrials/2) # 39 - 40 depends...\n",
    "    pre = x[:,:CondCutoff] # 24 x 39 - 40 depends ...\n",
    "    post = x[:,CondCutoff:]\n",
    "    AmpPerBin = np.ones((DomainCutoff,NumHarms)) # [bins (2f1 then 4f1)] X [pre /post] \\ 12 x 2\n",
    "    for RowInd in range(DomainCutoff):\n",
    "        ################ combining data generated from real and imaginary comp (1st half of cols and last half)\n",
    "        AmpPerBin[RowInd,0] = np.hypot(np.nanmean(pre[RowInd,:]),np.nanmean(pre[RowInd+DomainCutoff,:])) # 12 x 78 PRE\n",
    "        AmpPerBin[RowInd,1] = np.hypot(np.nanmean(post[RowInd,:]),np.nanmean(post[RowInd+DomainCutoff,:])) # 12 x 78 POST\n",
    "    return AmpPerBin # single array output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumBins = 6 # number of contrasts\n",
    "NumHarms = 2 # number of harmonic data: 2F1, 4F1\n",
    "NumComp = 0 # first component from RCA\n",
    "NumConds = 4\n",
    "dk_labs = ['attnL F1','attnL F2','attnR F1','attnR F2',]\n",
    "contrast_levels=np.array([1, 3, 5, 16, 40, 100])\n",
    "contrast_levels_labs=['1%', '3%', '5%', '16%', '40%', '100%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sns.color_palette(\"husl\", 8)\n",
    "y = sns.color_palette(\"hls\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files on hand: ['AllRCAData_20240209_133825.pkl', 'AllRCAData_pnlApp_20240228_155211.pkl', 'AllRCAData_pnlApp_20240229_110438.pkl']\n",
      "Current WD: C:\\plimon\\LTP_analysis\\RCA_F1\\AllSubjSweepRCA\\AllRCAData_pnlApp_20240229_110438.pkl\n",
      "Does File #1 Exist? True\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "# MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AllSubjSweepRCA\\\\' # set dir\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\AllSubjSweepRCA\\\\' # set dir\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "d = os.listdir(MainDir) # list files in dir\n",
    "print(f'Files on hand: {d}')\n",
    "##############################################\n",
    "FileN = d[-1] # choose one                        \n",
    "file_path1 = os.path.join(MainDir, FileN) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to Save Figures is: C:\\plimon\\LTP_analysis\\TwoSessionPlots_LTP\\CRF_plots\n"
     ]
    }
   ],
   "source": [
    "# SaveFigDir = 'D:\\\\AttnXV3_analysis\\\\TwoSessionPlots_LTP\\\\'\n",
    "SaveFigDir = 'C:\\\\plimon\\\\LTP_analysis\\\\TwoSessionPlots_LTP\\\\'\n",
    "SubFoldName = 'CRF_plots' # can change folder name to add to another folder now\n",
    "newPath = os.path.join(SaveFigDir,SubFoldName)\n",
    "if not os.path.exists(newPath):\n",
    "    os.makedirs(newPath)\n",
    "print('Path to Save Figures is:',newPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1])\n"
     ]
    }
   ],
   "source": [
    "loadData = pkl.load(open(file_path1, 'rb'))\n",
    "print(loadData.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for double session subs\n",
      "dict_keys([0, 1, 2, 3, 'FullSessSubjNames', 'DataNotes'])\n",
      "Data for single session subs\n",
      "dict_keys([0, 1, 2, 3, 'AttnLSubNames', 'AttnRSubNames'])\n"
     ]
    }
   ],
   "source": [
    "print(f'Data for double session subs')\n",
    "print(loadData[0].keys())\n",
    "print(f'Data for single session subs')\n",
    "print(loadData[1].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Double Session Data + other important info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoSessData = loadData[0]\n",
    "#print(loadData[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "SubName = TwoSessData['FullSessSubjNames'] # suject names\n",
    "NumSubs = int(len(SubName)) # number of participants \n",
    "txt = TwoSessData['DataNotes'] # notes from file imported\n",
    "data2s_inds = list(TwoSessData.keys())[0:4]\n",
    "data_2s = {key: TwoSessData[key] for key in data2s_inds}\n",
    "print(data_2s.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Single Session Data + other important info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleSessData = loadData[1]\n",
    "#print(loadData[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3])\n",
      "['2660'] 1\n",
      "['2663' '2663' '2676' '2678'] 4\n"
     ]
    }
   ],
   "source": [
    "# import actual data \n",
    "data_1s_inds = list(SingleSessData.keys())[0:4]\n",
    "data_1s = {key: SingleSessData[key] for key in data_1s_inds}\n",
    "print(data_1s.keys())\n",
    "# Name subs who completed attnL only + counts\n",
    "attnLSubs = SingleSessData['AttnLSubNames']\n",
    "NumSubs_l = int(len(attnLSubs))\n",
    "print(attnLSubs, NumSubs_l)\n",
    "# Name subs who completed attnR only + counts\n",
    "attnRSubs = SingleSessData['AttnRSubNames']\n",
    "NumSubs_r = int(len(attnRSubs))\n",
    "print(attnRSubs, NumSubs_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubName = loadData['FullSessSubjNames']\n",
    "# NumSubs = len(SubName)\n",
    "# txt = loadData['DataNotes']\n",
    "# print(txt)\n",
    "# ### ... import actual data ...###\n",
    "# data_inds = list(loadData.keys())[2:6]\n",
    "# print(data_inds)\n",
    "# data = {key: loadData[key] for key in data_inds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Remove NaNs from RCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = {}\n",
    "for data_set_ind in range(NumConds):\n",
    "    data_out[data_set_ind] = {}  # Initialize inner dictionary for data_set_ind\n",
    "    for i in range(NumSubs):\n",
    "        # a dict of 4 with XSubs dict keys of data\n",
    "        data_out[data_set_ind][i] = CleanRCA(np.array(data_2s[data_set_ind][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "data_out_1Sess = {}\n",
    "\n",
    "for i in range(NumConds):\n",
    "    data_out_1Sess[i] = {}\n",
    "    if i == 0 or i == 1: \n",
    "        NumSubs = NumSubs_l\n",
    "    else:\n",
    "        NumSubs = NumSubs_r\n",
    "\n",
    "    for j in range(NumSubs):\n",
    "        data_out_1Sess[i][j] = CleanRCA(np.array(data_1s[i][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_iters = 2\n",
    "data_out_1Sess = {}\n",
    "\n",
    "\n",
    "for i in range(file_iters):\n",
    "    if i == 0: \n",
    "        NumSubs = NumSubs_l\n",
    "        print('getting attnL subs')\n",
    "    elif i ==1: \n",
    "        NumSubs = NumSubs_r\n",
    "\n",
    "    for data_set_ind in range(NumConds):\n",
    "        for tot_subs in range(NumSubs):\n",
    "            print(tot_subs)\n",
    "            print('getting attnR subs')\n",
    "            data_out_1Sess[data_set_ind][tot_subs] = CleanRCA(np.array(data_1s[data_set_ind[tot_subs]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out_1Sess = {}\n",
    "for data_set_ind in range(NumConds):\n",
    "    #data_out_1Sess[data_set_ind] = {}  # Initialize inner dictionary for data_set_ind\n",
    "    data_out_1Sess[data_set_ind] = CleanRCA(np.array(data_1s[data_set_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_out_1Sess.keys())\n",
    "print(len(data_out_1Sess[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Real and Imaginary Data and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCRF = {}\n",
    "for data_set_ind in range(4):\n",
    "    avgCRF[data_set_ind] = {}  # Initialize inner dictionary for data_set_ind\n",
    "    for i in range(NumSubs):\n",
    "        ds = np.array(data[data_set_ind][i])\n",
    "        dIn = np.squeeze(ds[:,0,:])\n",
    "        avgCRF[data_set_ind][i] = CombineRealImg(dIn,NumHarms = 2) # 12 x 2 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set save data dir \n",
    "# Set directory to save NR Data in ..new folder\n",
    "# SaveDataDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AvgCRFs\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "SaveDataDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\AvgCRFs\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "FileOutName = 'AllCondCRF_AllSess' # make sure this file changes each time you save\n",
    "######################################################\n",
    "dnt = datetime.now() # add date and time bc im wreckless when saving ..\n",
    "fdnt = dnt.strftime(\"%Y%m%d_%H%M\") # set the above as a string ...\n",
    "FileN = f'{FileOutName}_{fdnt}.pkl' \n",
    "MatLabFileN = f'{FileOutName}_{fdnt}.mat'\n",
    "\n",
    "NewFileNPath = os.path.join(SaveDataDir,FileN)\n",
    "Mat_NewFileNPath = os.path.join(SaveDataDir, MatLabFileN)\n",
    "\n",
    "print('Full New File Dir: ', NewFileNPath)\n",
    "print('Where matlab file will be stored',Mat_NewFileNPath )\n",
    "\n",
    "if not os.path.exists(SaveDataDir):\n",
    "    os.makedirs(SaveDataDir)\n",
    "print('Path to Save File is:',SaveDataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save All Original Contrast Response Functions into a .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another personal voice memo ...\n",
    "Note = ['This file contains all subjects who did both sessions, avg of CRF [12x2] array, original crfs']\n",
    "\n",
    "DictOut = {}\n",
    "DictOut['Data'] = avgCRF\n",
    "DictOut['SubNames'] = SubName\n",
    "DictOut['VoiceMemo'] = Note\n",
    "DictOut['DictMainKeys'] = dk_labs\n",
    "DictOut['ContLevs'] = contrast_levels\n",
    "DictOut['crfLabs'] = contrast_levels_labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFile = 'n'\n",
    "\n",
    "if saveFile == 'y':\n",
    " \n",
    " scipy.io.savemat(Mat_NewFileNPath,DictOut)\n",
    "\n",
    " with open(NewFileNPath, 'wb') as file:\n",
    "    pkl.dump(DictOut, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    # save as .mat file or .csv file to import into matlab \n",
    "    \n",
    "    print('Average CRF Saved! :))')\n",
    "else:\n",
    "    print('Did Not Save File! Change file name before switching to y!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Data - can only plot per harmonic right now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "dpi = 150 # img res\n",
    "for sub_ind in range(NumSubs):\n",
    "    fig, axs = plt.subplots(1,4,figsize = (16,4), sharey = True )\n",
    "    for c in range(NumConds):\n",
    "        ImgName = (f'Sub_{SubName[sub_ind]}_data4F_.png')\n",
    "        axs[c].plot(avgCRF[c][sub_ind][:6,0], label = f' Pre {dk_labs[c]}', color = x[c], linewidth = 4, linestyle = '-.')\n",
    "        axs[c].plot(avgCRF[c][sub_ind][:6,1], label = f'Post {dk_labs[c]}', color = y[c], linewidth = 4)\n",
    "        axs[c].set_xlabel('Contrast %')\n",
    "        axs[c].set_ylabel('Amplitude (mV)')\n",
    "        axs[c].legend(loc = 'lower right')\n",
    "        axs[c].set_xticks(range(len(contrast_levels_labs)))\n",
    "        axs[c].set_xticklabels(contrast_levels_labs)\n",
    "        plt.suptitle(f'CRF For all sessions (1st Harmonic), Sub: {SubName[sub_ind]}')\n",
    "        #ImgPath = os.path.join(newPath, ImgName)\n",
    "        #plt.savefig(ImgPath, dpi = dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rent = 3438.47\n",
    "# ollie_rent = 65\n",
    "# addnl_extra_g = 100\n",
    "# g_extra = ollie_rent+addnl_extra_g # total extra \n",
    "# print(g_extra)\n",
    "# post_extra_rent = rent - g_extra\n",
    "# print(post_extra_rent)\n",
    "# P_base_rent = post_extra_rent/2\n",
    "# G_base_rent = (post_extra_rent/2)+ g_extra\n",
    "# print(f'Patis total rent {P_base_rent}')\n",
    "# print(f'Glos total rent {G_base_rent}')\n",
    "# san_check = P_base_rent + G_base_rent\n",
    "# print(rent , san_check)\n",
    "# print(rent == san_check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
