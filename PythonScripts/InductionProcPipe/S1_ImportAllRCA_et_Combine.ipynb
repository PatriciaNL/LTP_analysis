{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP ONE** OF DATA PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This script imports data in which a Reliable Component Analysis was performed. Visual Stimulus was dual frequency tagged: F1 = 1 Hz(1.5), F2 = 1.5 Hz (3) (inverting stim). Each participant completed 2 sessions. For each session, a F1 and F2 bandpass filter was performed. So 1 single participant has 4 data files. This is for a frequency-based analysis of the indution stage of the LTP paradigm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy.io\n",
    "from scipy.io   import  loadmat\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from scipy.optimize import curve_fit \n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviable Files to choose from: 2\n",
      "Files on hand: ['rcaResults_F1_Induction.mat', 'rcaResults_F2_Induction.mat']\n",
      "Current WD: C:\\plimon\\LTP_analysis\\RCA_F1\\Induction_RCA\\rcaResults_F1_Induction.mat\n",
      "Does File #1 Exist? True\n",
      "Current WD: C:\\plimon\\LTP_analysis\\RCA_F1\\Induction_RCA\\rcaResults_F2_Induction.mat\n",
      "Does File #2 Exist? True\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "#MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\RCA\\\\' # set dir - with USB Drive\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\Induction_RCA\\\\' # set dir - on my computer\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "d = os.listdir(MainDir) # list files in dir\n",
    "print(f'Aviable Files to choose from: {len(d)}')\n",
    "print(f'Files on hand: {d}')\n",
    "##############################################\n",
    "FileN_f1 = d[0] # choose one\n",
    "FileN_f2  = d[1]                         \n",
    "file_path1 = os.path.join(MainDir, FileN_f1) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no\n",
    "\n",
    "file_path2 = os.path.join(MainDir, FileN_f2) # join paths and prep 2 load\n",
    "print('Current WD:',file_path2) # does path exist ... ?\n",
    "print('Does File #2 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to save data:C:\\plimon\\LTP_analysis\\RCA_F1\\AllSubjInductRCA\\\n",
      "Full New File Dir:  C:\\plimon\\LTP_analysis\\RCA_F1\\AllSubjInductRCA\\All_Induct_RCA_20240320_125450.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Data Dir ...\n",
    "#SaveDataDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AllSubjSweepRCA\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "SaveDataDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\AllSubjInductRCA\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "FileOutName = 'All_Induct_RCA' \n",
    "newPath = os.path.join(SaveDataDir, FileOutName)\n",
    "if not os.path.exists(SaveDataDir):\n",
    "    os.makedirs(SaveDataDir)\n",
    "print(f'Path to save data:{SaveDataDir}')\n",
    "######################################################\n",
    "dnt = datetime.now() # add date and time bc im wreckless when saving ..\n",
    "fdnt = dnt.strftime(\"%Y%m%d_%H%M%S\") # set the above as a string ...\n",
    "FileN = f'{FileOutName}_{fdnt}.pkl' \n",
    "#FileNToMatlab = f'{FileOutName}_{fdnt}.h5' \n",
    "#FileN = f'{FileOutName}_{fdnt}.csv' \n",
    "NewFileNPath = os.path.join(SaveDataDir,FileN)\n",
    "print('Full New File Dir: ', NewFileNPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1 = scipy.io.loadmat(file_path1)\n",
    "df_f2 = scipy.io.loadmat(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load F1 and F2 RCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_f1 = df_f1['rcaResult']['projectedData'][0,0]\n",
    "f1 = [rca_f1[x,0] for x in range(rca_f1.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_f2 = df_f2['rcaResult']['projectedData'][0,0]\n",
    "f2 = [rca_f2[x,0] for x in range(rca_f2.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Files: 66\n"
     ]
    }
   ],
   "source": [
    "# load subject names ...\n",
    "SubNames = df_f1['rcaResult'][0,0][5]\n",
    "FileName = [x[0][3:] for subjlist in SubNames for x in subjlist[0][2][0]]\n",
    "#FileName = np.sort(FileName)\n",
    "print(f'Total Data Files: {len(FileName)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Subj Session Name Format Uniform and extract sub ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all file names to the same hyphen format\n",
    "FileName = [FileName.replace('_','-') for FileName in FileName]\n",
    "print(len(FileName))\n",
    "#### Set some params we'll need\n",
    "[NumCols, NumComps, b] = np.shape(f1[0]) # 24 x 4 x n-Trials\n",
    "NumFiles = int(len(FileName))\n",
    "\n",
    "print(NumCols,NumComps, b) # new data dims \n",
    "# Find How Many Subject Names There are ...\n",
    "string_ind = '-'\n",
    "uniqueSubs = []\n",
    "SessFileType = []\n",
    "for n in range(NumFiles):\n",
    "    x = FileName[n] # single file name string ie: 'nl-xxxx_attnX'\n",
    "    if string_ind in x:\n",
    "        y = x.split(string_ind)[0] # subj number\n",
    "        z = x.split(string_ind)[1] # session condition name \n",
    "        # from each session name extract import info that will help us index and exclude later on ..\n",
    "        uniqueSubs.append(y) # store all participant numbers (repeating - will be sorted later)\n",
    "        SessFileType.append(z) # store the condtion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given double sessions.., how many unique participants do we have?\n",
    "TotalFiles = np.array(uniqueSubs)\n",
    "[NumSubs, SessCounts] = np.unique(TotalFiles, return_counts = True) # returns unique subject and how many sessions they did (should be 2)\n",
    "print(f'Total Participants: {len(NumSubs)}')\n",
    "[FileQuants, TotSess] = np.unique(SessCounts, return_counts = True) # returns counts of how many subs did 1 session and 2 sessions \n",
    "print(f'{TotSess[1]} Participants completed the study')\n",
    "print(f'{TotSess[0]} Participants did not complete the study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwoSess = SessCounts == 2 # index of who completed 2 sessions ..\n",
    "GoodSubjs = NumSubs[TwoSess] # subs who completed 2 sessions \n",
    "SingleSessSubjs = NumSubs[~TwoSess] # subs who did not complete 2 sessions \n",
    "print(f'Subjects with 2 files: {len(GoodSubjs)}')\n",
    "print(GoodSubjs)\n",
    "print()\n",
    "print(f'Single Subjs: {SingleSessSubjs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes sure paticipants did complete attnL and attnR\n",
    "FNameCrit = ['attnL', 'attnR'] # session names \n",
    "CleanSubjs = [] \n",
    "\n",
    "for i in range(len(GoodSubjs)):\n",
    "    subj = GoodSubjs[i]\n",
    "    f_list = [x for x in FileName if subj in x] # import all strongs were sub number is \n",
    "    list_check  = np.sort(f_list) # abc order strings -  attnL and THEN attnR\n",
    "    counter = 0\n",
    "    for n in range(len(FNameCrit)):\n",
    "        if FNameCrit[n] in list_check[n]: # expt label should match file name in same position\n",
    "            counter = counter + 1 # if so add 1 \n",
    "            if (n == 1) and (counter == 2): # if both files strings are different, append\n",
    "                CleanSubjs.append(GoodSubjs[i])\n",
    "        else: # if not, add em to the singletons ... \n",
    "            print(f'{GoodSubjs[i]} did not match file name for {FNameCrit[n]}, moving subj to proper file ind array')\n",
    "            str_nm = (np.array([GoodSubjs[i]], dtype=object))\n",
    "            SingleSubs = np.concatenate((str_nm, SingleSessSubjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(CleanSubjs)} Participants Completed AttnL and AttnR')\n",
    "print(f'{len(SingleSubs)} Participants did not complete both sessions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNameCrit = ['attnL', 'attnR']\n",
    "FilePos = np.zeros((len(CleanSubjs), 2))\n",
    "\n",
    "for name in range(len(CleanSubjs)):\n",
    "    yIn = CleanSubjs[name] # import single subject who completed 2 sessions \n",
    "    all_files_avil = [x for x in FileName if yIn in x] # list\n",
    "    #all_files_avil = np.sort(all_files_avil) # might not be necessary but jic ...\n",
    "    pos = [loc for loc, file in enumerate(FileName) if file in all_files_avil] # index position of files if files match attnL and attnR\n",
    "    FilePos[name,:] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Now iterating through {NumFiles} files to sort doub sess positions\\\n",
    "({len(CleanSubjs)}), each subj has 2 file positions\\\n",
    " : AttnL and AttnR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttnL =  {'F1': [], 'F2': []} \n",
    "AttnR =  {'F1': [], 'F2': []} \n",
    "\n",
    "# run a different file we imported (2 F1 and F2 filtered data) to save all in the same file\n",
    "for dtaFile in range(3): # iterate through sessions \n",
    "        for ind in range(len(CleanSubjs)): # import 1 subjects file positions for attnL attnR\n",
    "            #print(iter,ind)\n",
    "            attnL_FilePos = int(FilePos[ind,0]) # element pos of attnL\n",
    "            attnR_FilePos = int(FilePos[ind,1]) # element pos of attnR \n",
    "\n",
    "            #print(attnL_FilePos,attnR_FilePos)\n",
    "            if dtaFile == 0:\n",
    "                data = f1\n",
    "                AttnL['F1'].append(data[attnL_FilePos])  # Append value to list in 'F1' key\n",
    "                AttnR['F1'].append(data[attnR_FilePos])  # Append value to list in 'F1' key\n",
    "            elif dtaFile == 1:\n",
    "                data = f2\n",
    "                #print(f'{attnL_FilePos,attnR_FilePos}')\n",
    "                AttnL['F2'].append(data[attnL_FilePos])  # Append value to list in 'F2' key\n",
    "                AttnR['F2'].append(data[attnR_FilePos])  # Append value to list in 'F2' key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f1),len(f2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
