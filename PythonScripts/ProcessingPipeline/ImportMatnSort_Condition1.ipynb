{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "import mne\n",
    "from mne.viz import plot_topomap\n",
    "from mne.viz import set_3d_title, set_3d_view\n",
    "sns.set_theme() # set the plotting atmosphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all files that will be sorted and exported from + into another .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files Avilable: 1\n",
      "Current WD: C:\\plimon\\LTP_analysis\\eegMatFiles\\AllMAT\\AllSubj_MatFiles_C1_20240412_110418.pkl\n",
      "Does File #1 Exist? True\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "#MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AvgCRFs\\\\' # set dir\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegMatFiles\\\\AllMAT' # set dir\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "dataFileNames = os.listdir(MainDir) # list files in dir\n",
    "print(f'Total Files Avilable: {len(dataFileNames)}')\n",
    "##############################################\n",
    "FileN = dataFileNames[0]# choose one                        \n",
    "file_path1 = os.path.join(MainDir, FileN) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumBins = 6\n",
    "NumHarms = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Keys in original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['RawData', 'SubjNames'])\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "loadData = pkl.load(open(file_path1, 'rb'))\n",
    "print(loadData.keys())\n",
    "print(len(loadData['RawData'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDims(DictIn):\n",
    "    \"\"\"This script gets the dims of data \n",
    "    for later indexing\"\"\"\n",
    "    iter = int(len(DictIn.keys())-1)\n",
    "    NumDims = np.zeros((int(iter),3))\n",
    "    for Sind in range(iter):\n",
    "        NumDims[Sind,:] = DictIn[Sind].shape\n",
    "    return NumDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variability of Rows: (array([112., 126.]), array([10, 39], dtype=int64))\n",
      "Variability of Chans: [128.]\n",
      "Variability of Trials: (array([78., 80.]), array([47,  2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "Dims = GetDims(loadData['RawData']) # shape of all subjs data\n",
    "\n",
    "print(f'Variability of Rows: {np.unique(Dims[:,0],return_counts = True)}')\n",
    "print(f'Variability of Chans: {np.unique(Dims[:,1])}')\n",
    "print(f'Variability of Trials: {np.unique(Dims[:,2], return_counts = True)}')\n",
    "\n",
    "NumChans = ((np.unique(Dims[:,1])))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_iters = int(Dims.shape[0])\n",
    "\n",
    "splitRowInd = []\n",
    "splitCondInd = []\n",
    "\n",
    "for sIn in range(s_iters):\n",
    "    dataDimsIn= Dims[sIn,:] # info for indexing rows, cols and trials\n",
    "    splitRowInd.append(int((dataDimsIn[0]/2))) # cutoff for splitting data along real-imag axis\n",
    "    splitCondInd.append(int(dataDimsIn[2]/2)) # cutoff for splitting trials as pre and post  \n",
    "splitRowInd = np.array(splitRowInd)\n",
    "splitCondInd = np.array(splitCondInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Channels of Interest to Visualize Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels to be visualized: [ 30  36  40  41  44  45  46  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98 100 101 102 106 107 112]\n"
     ]
    }
   ],
   "source": [
    "elecLeftLateral=[51,52,60,58,59,64,65,68,69]\n",
    "elecLeftMedial=[72,75,81,70,71,74]\n",
    "elecRightMedial=[72,75,81,76,83,82]\n",
    "elecMedial=[72,75,81,70,71,74,76,83,82]\n",
    "elecRightLateral=[97,92,85,96,91,95,90,94,88]\n",
    "extraChans = np.arange(50,100,1)\n",
    "extra = [107,101,47,42,37,31,102,46,41,45,49,103,108,113,108,99]\n",
    "AnalysisChans = [elecLeftLateral,elecLeftMedial,elecRightMedial,elecMedial,elecRightLateral,extraChans,extra]\n",
    "ExportChans = np.unique(np.sort(np.concatenate(AnalysisChans))) # Combine array for chans of interest\n",
    "VisChans  = ExportChans - 1\n",
    "print(f'Channels to be visualized: {VisChans}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Bool mask for MNE Topoplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanList = np.arange(0,Dims[0,1],1)\n",
    "ocm = np.zeros_like((chanList))\n",
    "ocm[VisChans] = True # set good chans to true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Real and Imaginary Components of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe has to add a mask before hypot is computed\n",
    "cleanData = {}\n",
    "for sIn in range(s_iters):\n",
    "    RawData = loadData['RawData'][sIn]\n",
    "     # reshape data so 0 = real and 1 = imaginary values \n",
    "    reshapeData  = RawData.reshape((splitRowInd[sIn]),2,int(Dims[sIn,1]),int(Dims[sIn,2]))\n",
    "    # replace bad chans with nan's\n",
    "    reshapeData[reshapeData == 0] = np.nan\n",
    "    # empty dataframe\n",
    "    comboData = np.zeros((splitRowInd[sIn],int(Dims[sIn,1]),int(Dims[sIn,2])))\n",
    "    unique_Iter = splitRowInd[sIn]\n",
    "    for val in range(unique_Iter):\n",
    "        comboData[val,:,:] = np.hypot(reshapeData[val,0,:,:],reshapeData[val,1,:,:])\n",
    "    cleanData[sIn] = comboData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data Per Bin and Store in Dict, Remove Prelude Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preBins = NumBins + 1 #(+1 bc prelude bin)\n",
    "GoodBinData = {}\n",
    "\n",
    "for sIn in range(s_iters):\n",
    "    dIn = cleanData[sIn] # import 1 subjs data \n",
    "    rmvBinInd = np.array(np.arange(0,splitRowInd[sIn],preBins)) # set indices to remove 1st (oth bin) out of every 7th\n",
    "    ind_arr = np.ones(splitRowInd[sIn]) # all rows good as default\n",
    "    ind_arr[rmvBinInd] = False # id prelude bins\n",
    "    GoodBinData[sIn] = dIn[ind_arr == 1,:,:] # save into dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Point #1** : Make sure 1F1 harmonic data is **NOT** included in analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File # 0 contains 1F1 data, now removing ...\n",
      "Data File # 1 contains 1F1 data, now removing ...\n",
      "Data File # 2 contains 1F1 data, now removing ...\n",
      "Data File # 3 contains 1F1 data, now removing ...\n",
      "Data File # 4 contains 1F1 data, now removing ...\n",
      "Data File # 5 contains 1F1 data, now removing ...\n",
      "Data File # 6 contains 1F1 data, now removing ...\n",
      "Data File # 7 contains 1F1 data, now removing ...\n",
      "Data File # 8 contains 1F1 data, now removing ...\n",
      "Data File # 9 contains 1F1 data, now removing ...\n",
      "Data File # 10 contains 1F1 data, now removing ...\n",
      "Data File # 11 contains 1F1 data, now removing ...\n",
      "Data File # 12 contains 1F1 data, now removing ...\n",
      "Data File # 13 contains 1F1 data, now removing ...\n",
      "Data File # 14 contains 1F1 data, now removing ...\n",
      "Data File # 15 contains 1F1 data, now removing ...\n",
      "Data File # 16 contains 1F1 data, now removing ...\n",
      "Data File # 17 contains 1F1 data, now removing ...\n",
      "Data File # 18 contains 1F1 data, now removing ...\n",
      "Data File # 19 contains 1F1 data, now removing ...\n",
      "Data File # 20 contains 1F1 data, now removing ...\n",
      "Data File # 21 contains 1F1 data, now removing ...\n",
      "Data File # 22 contains 1F1 data, now removing ...\n",
      "Data File # 23 contains 1F1 data, now removing ...\n",
      "Data File # 24 contains 1F1 data, now removing ...\n",
      "Data File # 25 contains 1F1 data, now removing ...\n",
      "Data File # 26 contains 1F1 data, now removing ...\n",
      "Data File # 27 contains 1F1 data, now removing ...\n",
      "Data File # 28 contains 1F1 data, now removing ...\n",
      "Data File # 29 contains 1F1 data, now removing ...\n",
      "Data File # 30 contains 1F1 data, now removing ...\n",
      "Data File # 31 contains 1F1 data, now removing ...\n",
      "Data File # 32 contains 1F1 data, now removing ...\n",
      "Data File # 33 contains 1F1 data, now removing ...\n",
      "Data File # 34 contains 1F1 data, now removing ...\n",
      "Data File # 35 contains 1F1 data, now removing ...\n",
      "File # 36 was preserved\n",
      "File # 37 was preserved\n",
      "File # 38 was preserved\n",
      "File # 39 was preserved\n",
      "File # 40 was preserved\n",
      "File # 41 was preserved\n",
      "File # 42 was preserved\n",
      "File # 43 was preserved\n",
      "Data File # 44 contains 1F1 data, now removing ...\n",
      "Data File # 45 contains 1F1 data, now removing ...\n",
      "File # 46 was preserved\n",
      "File # 47 was preserved\n",
      "Data File # 48 contains 1F1 data, now removing ...\n"
     ]
    }
   ],
   "source": [
    "HarmonicDataCo = 4 # should be 2f 4 f 6f and 8f data\n",
    "HemiFieldDataCo = 2 # should exist for f1 and f2\n",
    "idealHarmOrd = HarmonicDataCo*HemiFieldDataCo # 8\n",
    "\n",
    "allHemiData = {}\n",
    "for sIn in range(s_iters):\n",
    "# if data along rows is not divisible, remove 1f1 data\n",
    "    if (GoodBinData[sIn].shape[0] % idealHarmOrd) != 0:\n",
    "        print(f'Data File # {sIn} contains 1F1 data, now removing ...')\n",
    "        allHemiData[sIn] = GoodBinData[sIn][NumBins:,:,:] # remove the 1st 6 values of data \n",
    "    else:\n",
    "        print(f'File # {sIn} was preserved')\n",
    "        allHemiData[sIn] = GoodBinData[sIn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 and F2 data are stacked on top of each other so here we split them :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF1HemiData = {} # data is : 2f1 4f1 6f1 8f1\n",
    "xF2HemiData = {} # data is  2f2 4f2 6f2 8f2\n",
    "\n",
    "for sIn in range(s_iters):\n",
    "    HarmonicCutoff = int(allHemiData[sIn].shape[0] / 2)\n",
    "    xF1HemiData[sIn] = np.array(allHemiData[sIn][:HarmonicCutoff,:,:]) # harmonics x channels x trials  = 4 x 128 x 78\n",
    "    xF2HemiData[sIn] = np.array(allHemiData[sIn][HarmonicCutoff:,:,:]) # harmonics x channels x trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF1HemiBins = {}\n",
    "xF2HemiBins = {}\n",
    "for sIn in range(s_iters):\n",
    "    x1 = xF1HemiData[sIn]\n",
    "    x2 = xF2HemiData[sIn]\n",
    "    HarmonicEpochs = np.array(np.arange(0,x1.shape[0],NumBins)) # index to segment bins\n",
    "\n",
    "    xF1HemiBins[sIn] = {}\n",
    "    xF2HemiBins[sIn] = {}\n",
    "    for xFX in range(HarmonicDataCo):\n",
    "        xF1HemiBins[sIn][xFX] = x1[HarmonicEpochs[xFX]:HarmonicEpochs[xFX]+(NumBins),:,:]\n",
    "        xF2HemiBins[sIn][xFX] = x2[HarmonicEpochs[xFX]:HarmonicEpochs[xFX]+(NumBins),:,:]\n",
    "        #print(xF1HemiBins[sIn][xFX].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperate data into pre and post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSort(dictIn, sIn):\n",
    "    \"\"\"This function takes 1 subjects data.\n",
    "        Data contains 6 keys per bin.\n",
    "        Returns: Pre, Post and Post-Pre, and 2*(Post-Pre)/(Pre+Post) \"\"\"\n",
    "    BinDiffArith_Out = {}\n",
    "    BinBaseDiff_Out = {}\n",
    "    BinPrePost_Out = {}\n",
    "    fx = dictIn[sIn] # import data \n",
    "\n",
    "    for harmonic in range(NumHarms):\n",
    "\n",
    "        fx_avg = np.zeros((NumBins,int(len(chanList)),2)) # bins x channel x pre/post\n",
    "        fx_diff = np.zeros((NumBins,int(len(chanList))))\n",
    "        fx_sum = np.zeros_like(fx_diff)\n",
    "        fx_diffArith = np.zeros_like(fx_diff)\n",
    "\n",
    "        nt = int((fx[harmonic].shape[2])/2)\n",
    "        fx_temp = np.reshape(fx[harmonic], newshape = (NumBins,int(NumChans),2,nt))\n",
    "        #get pre and post induction average\n",
    "        for induCo in range(2):\n",
    "            fx_avg[:,:,induCo] = np.nanmean(fx_temp[:,:,induCo,:], axis = 2) # 6 x 128 \n",
    "        for bin in range(NumBins):\n",
    "            fx_diff[bin,:] = fx_avg[bin,:,1] - fx_avg[bin,:,0] # post - pre\n",
    "            fx_sum[bin,:] = fx_avg[bin,:,1] + fx_avg[bin,:,0] \n",
    "            fx_diffArith[bin,:] = 2*(((fx_diff[bin,:])/(fx_sum[bin,:])))\n",
    "\n",
    "        BinDiffArith_Out[harmonic] = fx_diffArith\n",
    "        BinBaseDiff_Out[harmonic] = fx_diff\n",
    "        BinPrePost_Out[harmonic] = fx_avg\n",
    "\n",
    "    return BinDiffArith_Out,BinBaseDiff_Out,BinPrePost_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plimon\\AppData\\Local\\Temp\\ipykernel_25136\\48880120.py:21: RuntimeWarning: Mean of empty slice\n",
      "  fx_avg[:,:,induCo] = np.nanmean(fx_temp[:,:,induCo,:], axis = 2) # 6 x 128\n"
     ]
    }
   ],
   "source": [
    "bda = {}\n",
    "bbd = {}\n",
    "bpp = {}\n",
    "\n",
    "for s in range(s_iters):\n",
    "    bda[s], bbd[s], bpp[s] = DataSort(xF1HemiBins, sIn = s)\n",
    "\n",
    "\n",
    "# bda, bbd , bpp  = DataSort(dictIn = xF1HemiBins, sIn = 20)\n",
    "# print(bda.keys())\n",
    "# print(bbd.keys())\n",
    "# print(bpp.keys())\n",
    "\n",
    "# print(bda[0].shape)\n",
    "# print(bbd[0].shape)\n",
    "# print(bpp[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DataSort()\n",
    "    \n",
    "sIn = 4    \n",
    "fx = xF1HemiBins[sIn]\n",
    "\n",
    "\n",
    "\n",
    "fx_sorted = {}\n",
    "fx_avg = np.zeros((NumBins,int(len(chanList)),2)) # bins x channel x pre/post\n",
    "fx_diff = np.zeros((NumBins,int(len(chanList))))\n",
    "fx_sum = np.zeros_like(fx_diff)\n",
    "fx_diffArith = np.zeros_like(fx_diff)\n",
    "\n",
    "for harmonic in range(NumHarms):\n",
    "    nt = int((fx[harmonic].shape[2])/2)\n",
    "    fx_temp = np.reshape(fx[harmonic], newshape = (NumBins,int(NumChans),2,nt))\n",
    "    #get pre and post inducrion average\n",
    "    for induCo in range(2):\n",
    "        fx_avg[:,:,induCo] = np.nanmean(fx_temp[:,:,induCo,:], axis = 2) # 6 x 128 \n",
    "\n",
    "    for bin in range(NumBins):\n",
    "        fx_diff[bin,:] = fx_avg[bin,:,1] - fx_avg[bin,:,0] # post - pre\n",
    "        fx_sum[bin,:] = fx_avg[bin,:,1] + fx_avg[bin,:,0] \n",
    "\n",
    "        fx_diffArith[bin,:] = 2*((fx_diff[bin,:])/(fx_sum[bin,:]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx_diffArith.shape\n",
    "\n",
    "for bin in range(NumBins):\n",
    "    plt.scatter(chanList,fx_diffArith[bin,:])\n",
    "plt.hlines(0, xmin = 0, xmax = 127, color = 'black', linewidth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_sorted[1].shape)\n",
    "\n",
    "pre_m1 = np.nanmean(f1_sorted[1][:,:,0,:], axis = 2)\n",
    "post_m1 = np.nanmean(f1_sorted[1][:,:,1,:],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre_m1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepost_bound= int(NumTrials/2) # reshape will occure at this ind \n",
    "\n",
    "xF1_pre_post = {} # F1 pre post data\n",
    "xF2_pre_post = {} # F2 pre post data\n",
    "\n",
    "for i in range(Bins):\n",
    "    xF1_pre_post[i] = np.reshape(xF1Bins[i], newshape = (4,NumChans,prepost_bound,2))\n",
    "    xF2_pre_post[i] = np.reshape(xF2Bins[i], newshape = (4,NumChans,prepost_bound,2)) # 4 x 128 x pre / post trials  x 2# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize data not for analysis - data is not comperable but more to make sure there is variance between trials, hemifields and harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickBin = 0\n",
    "pickTrial = 9\n",
    "print(f'channel activity per trial: harmonic, bin and hemifield')\n",
    "ch_list = np.arange(0,NumChans,1)\n",
    "\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF1_pre_post[pickBin][i,:,pickTrial,0], label = f'{(i+1)*2}F1 pre') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF1_pre_post[pickBin][i,:,pickTrial,1], label = f'{(i+1)*2}F1 post') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF2_pre_post[pickBin][i,:,pickTrial,0], label = f'{(i+1)*2}F2 pre') # plot per channel actiivity \n",
    "    plt.legend()\n",
    "plt.show()\n",
    "for i in range(4):\n",
    "    plt.scatter(ch_list,xF2_pre_post[pickBin][i,:,pickTrial,1], label = f'{(i+1)*2}F2 post') # plot per channel actiivity \n",
    "    plt.vlines(40, ymin = 0 , ymax = 3, color = 'black')\n",
    "    plt.vlines(100, ymin = 0, ymax = 3, color = 'black')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concate Data Across Bins to Get Average Activity Per Channel, Bin and Harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF1_CleanAvgs = {}\n",
    "xF2_CleanAvgs = {}\n",
    "\n",
    "for prepost in range(2):\n",
    "    xF1_CleanAvgs[prepost] = {} # make a new dict key for pre and then post \n",
    "    xF2_CleanAvgs[prepost] = {}\n",
    "    for bin in range(Bins):\n",
    "        #enter data dict\n",
    "        xF1_dIn = xF1_pre_post[bin] # 4  x 128 x ntrials x pre / post\n",
    "        xF2_dIn = xF2_pre_post[bin]\n",
    "        # avg harmonic activity per channel\n",
    "        xF1_CleanAvgs[prepost][bin] = np.nanmean(xF1_dIn[:,:,:,prepost],axis = -1) # average data per trial to get 1 val per channel\n",
    "        xF2_CleanAvgs[prepost][bin] = np.nanmean(xF2_dIn[:,:,:,prepost],axis = -1) # average data per trial to get 1 val per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepo = ['pre', 'post']\n",
    "\n",
    "binInd = 5\n",
    "fig, axs = plt.subplots(1,2,figsize = (10,5),sharey = True)\n",
    "for prepost in range(2):\n",
    "    dIn = xF1_CleanAvgs[prepost]\n",
    "    for hi in range(4):\n",
    "        axs[prepost].scatter(ch_list,dIn[binInd][hi,:], label = f'{(hi+1)*2}F1 {pepo[prepost]}')\n",
    "        axs[prepost].hlines(0,xmin = 0,xmax = 128, color = 'black')\n",
    "    plt.suptitle('XF1 average channel activity per bin')\n",
    "    axs[prepost].legend()\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize = (10,5),sharey = True)\n",
    "for prepost in range(2):\n",
    "    dIn = xF2_CleanAvgs[prepost]\n",
    "    for hi in range(4):\n",
    "        axs[prepost].scatter(ch_list,dIn[binInd][hi,:], label = f'{(hi+1)*2}F2 {pepo[prepost]}')\n",
    "        axs[prepost].hlines(0,xmin = 0,xmax = 128, color = 'black')\n",
    "    plt.suptitle('XF2 average channel activity per bin')\n",
    "    axs[prepost].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Data Across Harmonics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XF1_Data = {}\n",
    "XF2_Data = {}\n",
    "\n",
    "for prepost in range(2):\n",
    "    \n",
    "    XF1_Data[prepost] = {}\n",
    "    XF2_Data[prepost] = {}\n",
    "    temp_XF1 = np.concatenate([xF1_CleanAvgs[prepost][x] for x in xF1_CleanAvgs[prepost]])\n",
    "    temp_XF2 = np.concatenate([xF2_CleanAvgs[prepost][x] for x in xF2_CleanAvgs[prepost]])\n",
    "    XF1_Data[prepost] = np.reshape(temp_XF1, newshape = (4,Bins,NumChans))\n",
    "    XF2_Data[prepost] = np.reshape(temp_XF2, newshape =(4,Bins,NumChans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2, figsize = (12,6), sharey = True)\n",
    "plt.suptitle('Pre  + Post Channel Activity XF2')\n",
    "for pltpos in range(2):\n",
    "    pepo = XF2_Data[pltpos] # plot pre and post data\n",
    "    for i in range(Bins):\n",
    "        harmtwo  = pepo[0,i,:]\n",
    "        ht = np.nanmean(harmtwo,axis = 0) # 128 points of avg channel activity pre or post \n",
    "        axs[pltpos].scatter(ch_list,harmtwo, label = f'Bin: {i}')\n",
    "        axs[pltpos].legend()\n",
    "# plt.title(f'activity per channel across all bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Difference in Response Activity Post - Pre Induction\n",
    "## Method # 1: Post - Pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF1 Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_temp_pre = XF1_Data[0] # 4 x 6 x 128\n",
    "f1_temp_post = XF1_Data[1] # 4 x 6 x 128\n",
    "\n",
    "XF1_diffs = np.zeros_like((f1_temp_pre)) # temporary store of data \n",
    "\n",
    "for hi in range(4):\n",
    "    for bin in range(Bins):\n",
    "        diff = (f1_temp_post[hi,bin,:] - f1_temp_pre[hi,bin,:])\n",
    "        XF1_diffs[hi,bin,:] = diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_temp_pre = XF2_Data[0] # 4 x 6 x 128\n",
    "f2_temp_post = XF2_Data[1] # 4 x 6 x 128\n",
    "\n",
    "XF2_diffs = np.zeros_like((f2_temp_pre)) # temporary store of data \n",
    "\n",
    "for hi in range(4):\n",
    "    for bin in range(Bins):\n",
    "        diff = (f2_temp_post[hi,bin,:] - f2_temp_pre[hi,bin,:])\n",
    "        XF2_diffs[hi,bin,:] = diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Checkpoint #2** Before Plotting Topos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.sum(XF1_diffs == XF2_diffs) == 0:\n",
    "    print(f'Data does not overlap, good sign') # check if data is the same\n",
    "else:\n",
    "    print(f'check data indcies as data is the same for both hemifields')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Harmonic Data to Visualize, transpose data and Add Dead Channel for Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Harmonic = 0 # pick harmoic data to plot on topo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF1 Difference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_Diffs = XF1_diffs[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "print(F1_Diffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XF2 Difference Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F2_Diffs = XF2_diffs[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "print(F2_Diffs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select EEG Montage for MNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Set EEG Sensor Location File and Set as Default Montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eegMontageDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegSensorLocs\\\\9_18AverageNet128_v1.sfp'#AdultAverageNet128_v1.sfp'\n",
    "# # Check if the file exists\n",
    "# if os.path.exists(eegMontageDir):\n",
    "#     # Load the electrode locations file\n",
    "#     montageIn = mne.channels.read_custom_montage(eegMontageDir) # import file\n",
    "#     print(\"Electrode locations loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"The specified file does not exist.\")\n",
    "# print(montageIn)\n",
    "# #### Get channel names to use\n",
    "# info = mne.create_info(ch_names=montageIn.ch_names, sfreq=1, ch_types=\"eeg\")\n",
    "# info.set_montage(montageIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montageIn = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "info = mne.create_info(ch_names=montageIn.ch_names, sfreq=1, ch_types=\"eeg\")\n",
    "info.set_montage(montageIn)\n",
    "print(montageIn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF1_Data[0]\n",
    "data = p[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 10),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f' Pre F1 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i] # plot data per bin\n",
    "    # hashtag below to plot all channel activity\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 4)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF1_Data[1]\n",
    "data = p[Harmonic,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Post F1 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot F1 Difference post induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'F1 response change post induction, Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = F1_Diffs[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ploting F2 Data Now, 2nd harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF2_Data[0]\n",
    "\n",
    "data = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Pre F2 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i] # 129 array\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = XF2_Data[1]\n",
    "data = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "\n",
    "for i in range(Bins):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'Post F2 Bin # {i+1}', fontsize = 30)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = data[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 4)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Bins):\n",
    "    #plt.plot(topodata[:,i])\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 12),gridspec_kw=dict(height_ratios=[3]))\n",
    "    axes.set_title(f'F2 response change post induction, Bin # {i+1}', fontsize = 30)\n",
    "    #placeholder = np.random.random((10, 10))\n",
    "    #axs.imshow(placeholder)\n",
    "    axes.axis('off')\n",
    "\n",
    "    dataIn = F2_Diffs[:,i]\n",
    "    dataIn[~ocm] = 0 # want to index good channels only and set the rest channels to 0 value\n",
    "    im,_ = plot_topomap(dataIn, info,mask = ocm, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 3)\n",
    "    divider = make_axes_locatable(axes)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topodata = p[0,:,:].T\n",
    "# print(topodata.shape)\n",
    "# emptyChData = np.zeros((1,6))\n",
    "# print(emptyChData.shape)\n",
    "\n",
    "# dataFull = np.array(np.concatenate((topodata,emptyChData)))\n",
    "\n",
    "# data = dataFull[:,4]\n",
    "\n",
    "# # create array with 4 points for our 4 channels\n",
    "# # in the same order as provided in ch_names\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 10),gridspec_kw=dict(height_ratios=[3]))\n",
    "# axes.set_title(f'subj topo plot', fontsize = 30)\n",
    "# # placeholder = np.random.random((10, 10))\n",
    "# # axes.imshow(placeholder)\n",
    "# axes.axis('off')\n",
    "\n",
    "# #info = create_info(ch_names=montageIn._names, sfreq=1, ch_types='eeg')\n",
    "# # channel names I provided are part of a standard montage\n",
    "# #info.set_montage(montageIn) # import file)\n",
    "# im,_ = plot_topomap(data, info, axes = axes, show =False,cmap = 'Spectral_r', res = 32, contours = 8)\n",
    "# divider = make_axes_locatable(axes)\n",
    "# cax = divider.append_axes('right', size='5%', pad=0.2)\n",
    "# cbar = plt.colorbar(im, cax=cax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good confined example of what data formate is supposed to look like for mne plotting success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne import create_info\n",
    "# from mne.viz import plot_topomap\n",
    "# import numpy as np\n",
    "\n",
    "# # create array with 4 points for our 4 channels\n",
    "# # in the same order as provided in ch_names\n",
    "# data = np.random.randn(4)  \n",
    "# info = create_info(ch_names=['CPz', 'Oz', 'POz', 'Fz'], sfreq=1000, ch_types='eeg')\n",
    "# # channel names I provided are part of a standard montage\n",
    "# info.set_montage('standard_1020')\n",
    "\n",
    "# plot_topomap(data, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topodata = p[0,:,:].T  # 128 x 6 - 0 -== 2f\n",
    "# #have to add some fck channel data because egi file included one extra channel\n",
    "# emptyChData = np.zeros((1,6)) # 1 x 6\n",
    "# data = np.array(np.concatenate((topodata,emptyChData))) # 129 x 6 \n",
    "\n",
    "\n",
    "# for i in range(6):\n",
    "#     #plt.plot(topodata[:,i])\n",
    "#     fig, axs = plt.subplots(figsize = (6,6))\n",
    "#     axs.set_title(f'Bin # {i}')\n",
    "#     axs.legend()\n",
    "#     print(i)\n",
    "#     dataIn = data[:,i]\n",
    "#     mne.viz.plot_topomap(dataIn, info, axes = axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot formats of the past and present(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize = (10,10))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# montageIn.plot(kind='3d', axes=ax)\n",
    "# ax.set_title('Sensor Locations')\n",
    "# plt.show()\n",
    "# # Plot the sensors on a 2D head model\n",
    "# fig, ax = plt.subplots()\n",
    "# montageIn.plot(kind='topomap', show_names=True, axes=ax)\n",
    "# ax.set_title('Sensor Locations (2D)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #montge default info in case egi outut file fails me \n",
    "# montage_type = mne.channels.make_standard_montage(\"GSN-HydroCel-128\")\n",
    "# print(montage_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_label = ['2F','4F','6F','8F']\n",
    "\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF1_Data[0][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Pre F1 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "#plt.show()\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF1_Data[1][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Post F1 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF2_Data[0][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Pre F2 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')\n",
    "# fig,axs = plt.subplots(6,1, figsize = (10,40))\n",
    "# for i in range(6):\n",
    "#     dIn = axs[i].imshow(XF2_Data[1][:,i,ExportChans],aspect='auto', cmap=sns.cubehelix_palette(as_cmap=True))\n",
    "#     axs[i].set_xticks(np.arange(len(ExportChans)))\n",
    "#     axs[i].set_xticklabels(ExportChans,rotation=45)\n",
    "#     axs[i].set_yticks(np.arange(len(h_label)))  # Set y-ticks to match the length of y_labels\n",
    "#     axs[i].set_yticklabels(h_label) \n",
    "#     axs[i].set_title('Post F2 Data')\n",
    "#     axs[i].set_xlabel('Channels')\n",
    "#     axs[i].set_ylabel('Amplitude')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
