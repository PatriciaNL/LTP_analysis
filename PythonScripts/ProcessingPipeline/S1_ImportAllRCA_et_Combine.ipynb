{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP ONE** OF DATA PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This script imports data in which a Reliable Component Analysis was performed. Visual Stimulus was dual frequency tagged: F1 = 3 Hz(6), F2 = 3.75 Hs (7.5) (inverting stim). Each participant completed 2 sessions. For each session, a F1 and F2 bandpass filter was performed. So 1 single participant has 4 data files. This is for a frequency-based analysis of the LTP paradigm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy.io\n",
    "from scipy.io   import  loadmat\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from scipy.optimize import curve_fit \n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Dir Path(s): MainDir, SaveDataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviable Files to choose from: 8\n",
      "Files on hand: ['rcaResults_Sweep_contrast sweeps_F1_031324.mat', 'rcaResults_Sweep_contrast sweeps_F2_031324.mat', 'rcaResults_Sweep_contrast_sweeps_F1.mat', 'rcaResults_Sweep_contrast_sweeps_F2.mat', 'rcaResults_Sweep_Control_F1.mat', 'rcaResults_Sweep_Control_F2.mat', 'rcaResults_Sweep_F2F4F6F8_F1.mat', 'rcaResults_Sweep_F2F4F6F8_F2.mat']\n",
      "Current WD: C:\\plimon\\LTP_analysis\\RCA_F1\\RCA\\rcaResults_Sweep_Control_F1.mat\n",
      "Does File #1 Exist? True\n",
      "Current WD: C:\\plimon\\LTP_analysis\\RCA_F1\\RCA\\rcaResults_Sweep_Control_F2.mat\n",
      "Does File #2 Exist? True\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "#MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\RCA\\\\' # set dir - with USB Drive\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\RCA\\\\' # set dir - on my computer\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "d = os.listdir(MainDir) # list files in dir\n",
    "print(f'Aviable Files to choose from: {len(d)}')\n",
    "print(f'Files on hand: {d}')\n",
    "##############################################\n",
    "FileN_f1 = d[4] # choose one\n",
    "FileN_f2  = d[5]                         \n",
    "file_path1 = os.path.join(MainDir, FileN_f1) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no\n",
    "\n",
    "file_path2 = os.path.join(MainDir, FileN_f2) # join paths and prep 2 load\n",
    "print('Current WD:',file_path2) # does path exist ... ?\n",
    "print('Does File #2 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to save data:C:\\plimon\\LTP_analysis\\RCA_F1\\AllSubjSweepRCA\\\n",
      "Full New File Dir:  C:\\plimon\\LTP_analysis\\RCA_F1\\AllSubjSweepRCA\\AllSessionDataCombin_allHarms_20240404_150112.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save Data Dir ...\n",
    "#SaveDataDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AllSubjSweepRCA\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "SaveDataDir = 'C:\\\\plimon\\\\LTP_analysis\\\\RCA_F1\\\\AllSubjSweepRCA\\\\' # set dir where files (.pkl, .csv) will be saved\n",
    "FileOutName = 'AllSessionDataCombin_allHarms' \n",
    "newPath = os.path.join(SaveDataDir, FileOutName)\n",
    "if not os.path.exists(SaveDataDir):\n",
    "    os.makedirs(SaveDataDir)\n",
    "print(f'Path to save data:{SaveDataDir}')\n",
    "######################################################\n",
    "dnt = datetime.now() # add date and time bc im wreckless when saving ..\n",
    "fdnt = dnt.strftime(\"%Y%m%d_%H%M%S\") # set the above as a string ...\n",
    "FileN = f'{FileOutName}_{fdnt}.pkl' \n",
    "#FileNToMatlab = f'{FileOutName}_{fdnt}.h5' \n",
    "#FileN = f'{FileOutName}_{fdnt}.csv' \n",
    "NewFileNPath = os.path.join(SaveDataDir,FileN)\n",
    "print('Full New File Dir: ', NewFileNPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1 = scipy.io.loadmat(file_path1)\n",
    "df_f2 = scipy.io.loadmat(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load F1 and F2 RCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_f1 = df_f1['rcaResult']['projectedData'][0,0]\n",
    "f1 = [rca_f1[x,0] for x in range(rca_f1.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_f2 = df_f2['rcaResult']['projectedData'][0,0]\n",
    "f2 = [rca_f2[x,0] for x in range(rca_f2.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Files: 4\n"
     ]
    }
   ],
   "source": [
    "# load subject names ...\n",
    "SubNames = df_f1['rcaResult'][0,0][5]\n",
    "FileName = [x[0][3:] for subjlist in SubNames for x in subjlist[0][2][0]]\n",
    "#FileName = np.sort(FileName)\n",
    "print(f'Total Data Files: {len(FileName)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Subj Session Name Format Uniform and extract sub ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2738\n",
      "attnR\n",
      "345202\n",
      "attnR\n",
      "345215\n",
      "attnR\n",
      "345216\n",
      "attnR\n"
     ]
    }
   ],
   "source": [
    "# set all file names to the same hyphen format\n",
    "FileName = [FileName.replace('_','-') for FileName in FileName]\n",
    "print(len(FileName))\n",
    "#### Set some params we'll need\n",
    "[NumCols, NumComps, b] = np.shape(f1[0]) # 24 x 4 x n-Trials\n",
    "NumFiles = int(len(FileName))\n",
    "\n",
    "#print(NumCols,NumComps, b) # new data dims \n",
    "# Find How Many Subject Names There are ...\n",
    "string_ind = '-'\n",
    "uniqueSubs = []\n",
    "SessFileType = []\n",
    "for n in range(NumFiles):\n",
    "    x = FileName[n] # single file name string ie: 'nl-xxxx_attnX'\n",
    "    if string_ind in x:\n",
    "        y = x.split(string_ind)[0] # subj number\n",
    "        print(y)\n",
    "        z = x.split(string_ind)[1] # session condition name \n",
    "        print(z)\n",
    "        # from each session name extract import info that will help us index and exclude later on ..\n",
    "        uniqueSubs.append(y) # store all participant numbers (repeating - will be sorted later)\n",
    "        SessFileType.append(z) # store the condtion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Participants: 4\n"
     ]
    }
   ],
   "source": [
    "# given double sessions.., how many unique participants do we have?\n",
    "TotalFiles = np.array(uniqueSubs)\n",
    "[NumSubs, SessCounts] = np.unique(TotalFiles, return_counts = True) # returns unique subject and how many sessions they did (should be 2)\n",
    "print(f'Total Participants: {len(NumSubs)}')\n",
    "[FileQuants, TotSess] = np.unique(SessCounts, return_counts = True) # returns counts of how many subs did 1 session and 2 sessions \n",
    "print(f'{TotSess[1]} Participants completed the study')\n",
    "print(f'{TotSess[0]} Participants did not complete the study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects with 2 files: 0\n",
      "[]\n",
      "\n",
      "Single Subjs: ['2738' '345202' '345215' '345216']\n"
     ]
    }
   ],
   "source": [
    "TwoSess = SessCounts == 2 # index of who completed 2 sessions ..\n",
    "GoodSubjs = NumSubs[TwoSess] # subs who completed 2 sessions \n",
    "SingleSessSubjs = NumSubs[~TwoSess] # subs who did not complete 2 sessions \n",
    "print(f'Subjects with 2 files: {len(GoodSubjs)}')\n",
    "print(GoodSubjs)\n",
    "print()\n",
    "print(f'Single Subjs: {SingleSessSubjs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have to add this step because I ran someone for attnR **twice** ... yikes ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes sure paticipants did complete attnL and attnR\n",
    "FNameCrit = ['attnL', 'attnR'] # session names \n",
    "CleanSubjs = [] \n",
    "\n",
    "for i in range(len(GoodSubjs)):\n",
    "    subj = GoodSubjs[i]\n",
    "    f_list = [x for x in FileName if subj in x] # import all strongs were sub number is \n",
    "    list_check  = np.sort(f_list) # abc order strings -  attnL and THEN attnR\n",
    "    counter = 0\n",
    "    for n in range(len(FNameCrit)):\n",
    "        if FNameCrit[n] in list_check[n]: # expt label should match file name in same position\n",
    "            counter = counter + 1 # if so add 1 \n",
    "            if (n == 1) and (counter == 2): # if both files strings are different, append\n",
    "                CleanSubjs.append(GoodSubjs[i])\n",
    "        else: # if not, add em to the singletons ... \n",
    "            print(f'{GoodSubjs[i]} did not match file name for {FNameCrit[n]}, moving subj to proper file ind array')\n",
    "            str_nm = (np.array([GoodSubjs[i]], dtype=object))\n",
    "            SingleSubs = np.concatenate((str_nm, SingleSessSubjs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many participants **actually** completed both sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(CleanSubjs)} Participants Completed AttnL and AttnR')\n",
    "print(f'{len(SingleSubs)} Participants did not complete both sessions')\n",
    "print(CleanSubjs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Data Files as AttnL and AttnR in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNameCrit = ['attnL', 'attnR']\n",
    "FilePos = np.zeros((len(CleanSubjs), 2))\n",
    "\n",
    "for name in range(len(CleanSubjs)):\n",
    "    yIn = CleanSubjs[name] # import single subject who completed 2 sessions \n",
    "    all_files_avil = [x for x in FileName if yIn in x] # list\n",
    "    all_files_avil = np.sort(all_files_avil) # might not be necessary but jic ...\n",
    "    pos = [loc for loc, file in enumerate(FileName) if file in all_files_avil] # index position of files if files match attnL and attnR\n",
    "    FilePos[name,:] = pos\n",
    "#print(FilePos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a big for loop to save all this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "AttnL =  {'F1': [], 'F2': []} \n",
    "AttnR =  {'F1': [], 'F2': []} \n",
    "#AttnX =  {'F1': [], 'F2': []} \n",
    "\n",
    "# run a different file we imported (2 F1 and F2 filtered data) to save all in the same file\n",
    "for iter in range(NumFiles):\n",
    "    for ind in range(len(CleanSubjs)):\n",
    "        attnL_FilePos = int(FilePos[ind,0])\n",
    "        attnR_FilePos = int(FilePos[ind,1])\n",
    "        if iter == 0:\n",
    "            data = f1\n",
    "            AttnL['F1'].append(data[attnL_FilePos])  # Append value to list in 'F1' key\n",
    "            AttnR['F1'].append(data[attnR_FilePos])  # Append value to list in 'F1' key\n",
    "        elif iter == 1:\n",
    "            data = f2\n",
    "            AttnL['F2'].append(data[attnL_FilePos])  # Append value to list in 'F2' key\n",
    "            AttnR['F2'].append(data[attnR_FilePos])  # Append value to list in 'F2' key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Saving Subjects data who only completed 1 session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SingleSubs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m SingleFiles_arr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mSingleSubs\u001b[49m)):\n\u001b[0;32m      3\u001b[0m     subIn \u001b[38;5;241m=\u001b[39m SingleSubs[file] \u001b[38;5;66;03m# import one file at a time\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     files_avil \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m FileName \u001b[38;5;28;01mif\u001b[39;00m subIn \u001b[38;5;129;01min\u001b[39;00m x]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SingleSubs' is not defined"
     ]
    }
   ],
   "source": [
    "SingleFiles_arr = []\n",
    "for file in range(len(SingleSubs)):\n",
    "    subIn = SingleSubs[file] # import one file at a time\n",
    "    files_avil = [x for x in FileName if subIn in x]\n",
    "    SingleFiles_arr.append(files_avil)\n",
    "\n",
    "SinglefileNames = np.array(list(chain(*SingleFiles_arr))) #all single session names flattened\n",
    "print(SinglefileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SinglefileNames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m string_catch_L \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattnL\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m string_catch_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattnR\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m single_sess_ind \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(\u001b[43mSinglefileNames\u001b[49m)) \u001b[38;5;66;03m# size of single sessions available\u001b[39;00m\n\u001b[0;32m      4\u001b[0m SingleSessSubName \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# save subject name \u001b[39;00m\n\u001b[0;32m      5\u001b[0m single_sess_pos \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# find and store the data index \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SinglefileNames' is not defined"
     ]
    }
   ],
   "source": [
    "string_catch_L = 'attnL'\n",
    "string_catch_R = 'attnR'\n",
    "single_sess_ind = np.zeros(len(SinglefileNames)) # size of single sessions available\n",
    "SingleSessSubName = [] # save subject name \n",
    "single_sess_pos = [] # find and store the data index \n",
    "\n",
    "for sInFName in range(len(SinglefileNames)):\n",
    "    # determine whether its attnr or attnL\n",
    "    fIn = SinglefileNames[sInFName]\n",
    "    #find the postion of file in the data to organize later\n",
    "    pos = [posi for posi, file in enumerate(FileName) if file in fIn]\n",
    "    single_sess_pos.append(pos)\n",
    "\n",
    "    x = fIn.split(string_ind)[1]\n",
    "    y = fIn.split(string_ind)[0]\n",
    "    SingleSessSubName.append(y)\n",
    "    # make array to findex what files are attnL and attnR\n",
    "    if string_catch_L in x:\n",
    "        single_sess_ind[sInFName] = 1 # attnL ind == 1\n",
    "    elif string_catch_R in x:\n",
    "        single_sess_ind[sInFName] = 0 # attnL ind == 0\n",
    "\n",
    "single_sess_pos = np.array(single_sess_pos)\n",
    "# print(single_sess_pos)\n",
    "# print(single_sess_ind)\n",
    "# print(SingleSessSubName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index and save singles sessions as a seperate dict to export in pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SinglefileNames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m r_subs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NumFiles):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m oneSess \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mSinglefileNames\u001b[49m)):\n\u001b[0;32m      8\u001b[0m         sIn \u001b[38;5;241m=\u001b[39m SingleSessSubName[oneSess] \u001b[38;5;66;03m# single sub names\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         AttnXCond \u001b[38;5;241m=\u001b[39m single_sess_ind[oneSess] \u001b[38;5;66;03m# condtion they did\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SinglefileNames' is not defined"
     ]
    }
   ],
   "source": [
    "single_sess_AttnL =  {'F1': [], 'F2': []} \n",
    "single_sess_AttnR =  {'F1': [], 'F2': []} \n",
    "l_subs = []\n",
    "r_subs = []\n",
    "\n",
    "for file_op in range(NumFiles):\n",
    "    for oneSess in range(len(SinglefileNames)):\n",
    "        sIn = SingleSessSubName[oneSess] # single sub names\n",
    "        AttnXCond = single_sess_ind[oneSess] # condtion they did\n",
    "        DataPos = single_sess_pos[oneSess] # position of data file is \n",
    "        DataPos = int(DataPos[0]) \n",
    "\n",
    "        if file_op == 0:\n",
    "            dataIn = f1 # switch files 2 combine them\n",
    "            if AttnXCond == 1:\n",
    "                single_sess_AttnL['F1'].append(dataIn[DataPos]) # save data in this dict\n",
    "                l_subs.append(sIn) # save subject name in this dict\n",
    "            else:\n",
    "                single_sess_AttnR['F1'].append(dataIn[DataPos])\n",
    "                r_subs.append(sIn)\n",
    "\n",
    "        elif file_op == 1:\n",
    "            dataIn = f2 # switch files 2 combine them\n",
    "            if AttnXCond == 1:\n",
    "                single_sess_AttnL['F2'].append(dataIn[DataPos])\n",
    "            else:\n",
    "                single_sess_AttnR['F2'].append(dataIn[DataPos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 'AttnLSubNames', 'AttnRSubNames'])\n"
     ]
    }
   ],
   "source": [
    "SingleSessDataOut = {}\n",
    "\n",
    "SingleSessDataOut[0] = single_sess_AttnL['F1']\n",
    "SingleSessDataOut[1] = single_sess_AttnL['F2']\n",
    "SingleSessDataOut[2] = single_sess_AttnR['F1']\n",
    "SingleSessDataOut[3] = single_sess_AttnR['F2']\n",
    "\n",
    "SingleSessDataOut['AttnLSubNames'] = np.array(l_subs)\n",
    "SingleSessDataOut['AttnRSubNames'] = np.array(r_subs)\n",
    "#SingleSessDataOut['DataNotes'] = ['keys: 0&1 attnL[f1/f2] and 2&3 attR[f1/f2], single session data']\n",
    "print(SingleSessDataOut.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 'FullSessSubjNames', 'DataNotes'])\n"
     ]
    }
   ],
   "source": [
    "SessDataOut = {}\n",
    "\n",
    "SessDataOut[0] = AttnL['F1']\n",
    "SessDataOut[1] = AttnL['F2']\n",
    "SessDataOut[2] = AttnR['F1']\n",
    "SessDataOut[3] = AttnR['F2']\n",
    "\n",
    "SessDataOut['FullSessSubjNames'] = CleanSubjs\n",
    "SessDataOut['DataNotes'] = ['keys: 0&1 attnL[f1/f2] and 2&3 attR[f1/f2]']\n",
    "print(SessDataOut.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Data into .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOut = {}\n",
    "\n",
    "dataOut[0] = SessDataOut\n",
    "dataOut[1] = SingleSessDataOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Data Saved! :))\n"
     ]
    }
   ],
   "source": [
    "saveFile = 'y'\n",
    "\n",
    "if saveFile == 'y':\n",
    " with open(NewFileNPath, 'wb') as file:\n",
    "    pkl.dump(dataOut, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    print('Sorted Data Saved! :))')\n",
    "else:\n",
    "    print('Did Not Save File! Change file name before switching to y!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
