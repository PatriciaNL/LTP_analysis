{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np \n",
    "import scipy \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt #import matplotlib as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns #import mat73\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "import mne\n",
    "from mne.viz import plot_topomap\n",
    "from mne.io import RawArray\n",
    "import numpy.matlib\n",
    "sns.set_theme() # set the plotting atmosphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all files that will be sorted and exported into another .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files on hand: 50\n",
      "Current WD: C:\\plimon\\LTP_analysis\\eegMatFiles\\MAT\\nl-2666_attnL_20231023_1612_RLS.mat\n"
     ]
    }
   ],
   "source": [
    "# Main Directory of processed file from MatLab\n",
    "#MainDir = 'D:\\\\AttnXV3_analysis\\\\RCA_F1\\\\AvgCRFs\\\\' # set dir\n",
    "MainDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegMatFiles\\\\MAT' # set dir\n",
    "os.chdir(MainDir) # change old dir, to this dir\n",
    "d = os.listdir(MainDir) # list files in dir\n",
    "print(f'Number of Files on hand: {int(len(d))}')\n",
    "##############################################\n",
    "FileN = d[10] # choose one                        \n",
    "file_path1 = os.path.join(MainDir, FileN) # join paths and prep 2 load\n",
    "print('Current WD:',file_path1) # does path exist ... ?\n",
    "#print('Does File #1 Exist?',os.path.exists(file_path1)) # yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fnames = np.sort(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumHarms = 4\n",
    "NumBins = 6\n",
    "NumHemis = 2\n",
    "co = 0\n",
    "\n",
    "GoodDataDims = NumHarms*NumBins*NumHemis\n",
    "GoodKeyDicts = NumHarms*NumHemis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file # 0 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 0 good now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plimon\\AppData\\Local\\Temp\\ipykernel_5904\\1897023275.py:50: RuntimeWarning: Mean of empty slice\n",
      "  xt_comb[bin,1,ch] = np.hypot(np.nanmean(dIn[bin,0,ch,inds[1]:inds[2]]),np.nanmean(dIn[bin,1,ch,inds[1]:inds[2]])) # post\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file # 1 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 1 good now!\n",
      "data file # 2 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 2 good now!\n",
      "data file # 3 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 3 good now!\n",
      "data file # 4 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 4 good now!\n",
      "data file # 5 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 5 good now!\n",
      "data file # 6 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 6 good now!\n",
      "data file # 7 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 7 good now!\n",
      "data file # 8 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 8 good now!\n",
      "data file # 9 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 9 good now!\n",
      "data file # 10 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 10 good now!\n",
      "data file # 11 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 11 good now!\n",
      "data file # 12 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 12 good now!\n",
      "data file # 13 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 13 good now!\n",
      "data file # 14 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 14 good now!\n",
      "data file # 15 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 15 good now!\n",
      "data file # 16 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 16 good now!\n",
      "data file # 17 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 17 good now!\n",
      "data file # 18 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 18 good now!\n",
      "data file # 19 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 19 good now!\n",
      "data file # 20 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 20 good now!\n",
      "data file # 21 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 21 good now!\n",
      "data file # 22 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 22 good now!\n",
      "data file # 23 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 23 good now!\n",
      "data file # 24 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 24 good now!\n",
      "data file # 25 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 25 good now!\n",
      "data file # 26 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 26 good now!\n",
      "data file # 27 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 27 good now!\n",
      "data file # 28 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 28 good now!\n",
      "data file # 29 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 29 good now!\n",
      "data file # 30 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 30 good now!\n",
      "data file # 31 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 31 good now!\n",
      "data file # 32 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 32 good now!\n",
      "data file # 33 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 33 good now!\n",
      "data file # 34 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 34 good now!\n",
      "data file # 35 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 35 good now!\n",
      "data file # 44 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 44 good now!\n",
      "data file # 45 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 45 good now!\n",
      "data file # 48 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 48 good now!\n",
      "data file # 49 good now!\n",
      "f1 data is first key ... now removing\n",
      "real imaginary data file # 49 good now!\n"
     ]
    }
   ],
   "source": [
    "SignalData  = {} # ave average data \n",
    "RealnImaginaryData = {} # save real and imaginary data \n",
    "\n",
    "for suIn in range(len(d)):#range(10):# og d \n",
    "    RealnImaginaryData[suIn] = {}\n",
    "### import file path \n",
    "    FileN = Fnames[suIn] # import from sorted subj expt name list                       \n",
    "    file_path = os.path.join(MainDir, FileN) # join paths and prep 2 load\n",
    "    mat_data = scipy.io.loadmat(file_path) # import data file\n",
    "    # extract from file \n",
    "    MainData = mat_data['signalData'][co][0]\n",
    "    HarmInd = np.ravel(mat_data['info'][0][0][0][co][0])\n",
    "    BinInd = np.ravel(mat_data['info'][0][0][1][co][0])\n",
    "    SortIters , misc = np.unique(HarmInd, return_counts = True)\n",
    "    sIters = int(len(SortIters))\n",
    "### info for indexing and sorting \n",
    "    NumHarms,NumHarmCount = np.unique(HarmInd, return_counts = True)\n",
    "    BinCountArr,NumBinCount = np.unique(BinInd, return_counts = True)\n",
    "    SortDataIn = np.array(MainData)\n",
    "    [NumRows, NumChans, NumTrials] = SortDataIn.shape # get dims of data to use later ..\n",
    "    real_imag_bound = int((NumRows/2))\n",
    "    #print(f'Data real-imag bound is at row: #{real_imag_bound}')\n",
    "    chanInd = np.arange(1,NumChans,1)\n",
    "    prepost_bound = int(NumTrials/2)\n",
    "### reshape real and imaginary values and remove 0's with nan's\n",
    "    dIn = SortDataIn.reshape(real_imag_bound,2,NumChans,NumTrials,order='A')\n",
    "    # RealnImaginaryData[suIn]= dIn    \n",
    "    dIn[dIn==0]=np.nan\n",
    "### remove prelude bins from each contrast\n",
    "\n",
    "    xF_Bins = {}\n",
    "    for i in range(sIters):\n",
    "        xF_Bins[i]=dIn[HarmInd==i+1,:,:,:] # array begins at 1 - not 0 \n",
    "        if int(xF_Bins[i].shape[0])!=(NumBins): # remove prelude / avg contrast activity\n",
    "            temp=xF_Bins[i][1:,:,:,:] # all data w/o 0th row (not relevant data)\n",
    "            xF_Bins[i]=temp\n",
    "#             RealnImaginaryData[suIn][i]=xF_Bins[i] # save real and imaginary data\n",
    "# print(RealnImaginaryData[suIn].keys())\n",
    "### average ral and imaginary data based on pre / post\n",
    "    data = {}\n",
    "    ri_data = {}\n",
    "    for fritters in range(sIters):\n",
    "        xt_comb = np.zeros((NumBins,2,NumChans)) \n",
    "        dIn = xF_Bins[fritters]\n",
    "        tco = int((dIn.shape[3])/2) # pre post trial cutoff\n",
    "        inds = np.array(np.arange(0,tco*3,tco)) # trial pre post indcies \n",
    "        for bin in range(NumBins):\n",
    "            for ch in range(NumChans):\n",
    "                xt_comb[bin,0,ch] = np.hypot(np.nanmean(dIn[bin,0,ch,inds[0]:inds[1]]),np.nanmean(dIn[bin,1,ch,inds[0]:inds[1]])) # pre\n",
    "                xt_comb[bin,1,ch] = np.hypot(np.nanmean(dIn[bin,0,ch,inds[1]:inds[2]]),np.nanmean(dIn[bin,1,ch,inds[1]:inds[2]])) # post\n",
    "        data[fritters] = xt_comb\n",
    "        ri_data[fritters] = dIn\n",
    "    #print(ri_data.keys())\n",
    "\n",
    "    ### remove 1F1 data if it is present in avg pre pos data\n",
    "    if int(len(data.keys())) != GoodKeyDicts:\n",
    "        #print(f'f1 data is first key ... now removing')\n",
    "        del data[0] # rmv 1f1 data\n",
    "        dOut = {key - 1: value for key, value in data.items()} # reset dict vals to start at 0\n",
    "        SignalData[suIn] = dOut\n",
    "        if int(len(data.keys())) == GoodKeyDicts:\n",
    "            print(f'data file # {suIn} good now!')     \n",
    "    elif int(len(data.keys())) == GoodKeyDicts:\n",
    "        #print(f'Data file # {suIn} all good, will be stored!')\n",
    "        SignalData[suIn] = data\n",
    "\n",
    "    ### remove 1F1 data if it is present in real / imarinary data\n",
    "    if int(len(ri_data.keys())) != GoodKeyDicts:\n",
    "        print(f'f1 data is first key ... now removing')\n",
    "        del ri_data[0] # rmv 1f1 data\n",
    "        dOut_ri = {key - 1: value for key, value in ri_data.items()} # reset dict vals to start at 0\n",
    "        RealnImaginaryData[suIn] = dOut_ri\n",
    "        if int(len(ri_data.keys())) == GoodKeyDicts:\n",
    "            print(f'real imaginary data file # {suIn} good now!')\n",
    "    elif int(len(ri_data.keys())) == GoodKeyDicts:\n",
    "    #print(f'Data file # {suIn} all good, will be stored!')\n",
    "        RealnImaginaryData[suIn] = ri_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "(6, 2, 128, 78)\n"
     ]
    }
   ],
   "source": [
    "print(RealnImaginaryData.keys())\n",
    "print(RealnImaginaryData[0].keys())\n",
    "print(RealnImaginaryData[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sIn = 25\n",
    "\n",
    "# fig,axs = plt.subplots(8,2, figsize = (4,16), sharey = True)\n",
    "# d2p = SignalData[sIn]\n",
    "# print(d2p.keys())\n",
    "\n",
    "# for i in range(8):\n",
    "#     #print(d2p[i].shape)\n",
    "#     axs[i,0].plot(d2p[i][:,0,55:90])\n",
    "#     axs[i,1].plot(d2p[i][:,1,55:90])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort Condition Bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNamesIndicies = np.array(d) # make list into array \n",
    "FileName = [FileNamesIndicies.replace('_','-') for FileNamesIndicies in FileNamesIndicies] # uniform fnames to make bools for attnl and attnR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataOut = {}\n",
    "\n",
    "DataOut['RealImaginaryData_sIns'] = RealnImaginaryData\n",
    "DataOut['EEGData'] = SignalData\n",
    "DataOut['SubIDs'] = FileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Full New File Dir:  C:\\plimon\\LTP_analysis\\eegMatFiles\\AllMat\\AllSubj_MatFiles_ri_C1_20240502_151155.pkl\n",
      "MAT Data For All Subjs Saved! :))\n"
     ]
    }
   ],
   "source": [
    "SaveDataDir = 'C:\\\\plimon\\\\LTP_analysis\\\\eegMatFiles\\\\AllMat'\n",
    "print(os.path.exists(SaveDataDir)) # does pth exist :p\n",
    "\n",
    "dnt = datetime.now() # add date and time bc im wreckless when saving ..\n",
    "fdnt = dnt.strftime(\"%Y%m%d_%H%M%S\") # set the above as a string ...\n",
    "FileOutName = 'AllSubj_MatFiles_ri_C1'\n",
    "FileN = f'{FileOutName}_{fdnt}.pkl' \n",
    "NewFileNPath = os.path.join(SaveDataDir,FileN)\n",
    "print('Full New File Dir: ', NewFileNPath)\n",
    "\n",
    "saveFile = 'y'\n",
    "if saveFile == 'y':\n",
    " with open(NewFileNPath, 'wb') as file:\n",
    "    pkl.dump(DataOut, file, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    print('MAT Data For All Subjs Saved! :))')\n",
    "else:\n",
    "    print('Did Not Save File! Change file name before switching to y!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index certain keys for analysis and conditions during expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find basic data parms \n",
    "# MainData = mat_data['signalData']\n",
    "# noise1 = mat_data['noise1'] # 6 x 1 \n",
    "# noise2 = mat_data['noise2']\n",
    "# inds = mat_data['info'][0][0]\n",
    "# ExpConds = int(MainData.shape[0])\n",
    "# print(f'Data file contains data for {ExpConds} different conditions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elec_Arc1_outer = [68,64,58,51,47,42,37,31,    80,87,93,98,97,96,95,94]\n",
    "# elec_Arc2 = [73,69,65,59,52,53,54,  55,  79,86,92,91,90,89,88]\n",
    "# elec_Arc3 = [74,70,66,60,61,  78,85,84,83,82,  81]\n",
    "# elec_Arc4_inner = [71,67,62,77,76,75,     72]\n",
    "# AllAnalysisChans = np.concatenate([elec_Arc1_outer,elec_Arc2,elec_Arc3,elec_Arc4_inner])\n",
    "# #AllAnalysisChans = np.concatenate([elec_Arc2,elec_Arc3,elec_Arc4_inner])\n",
    "# AnalysisChans = np.unique(AllAnalysisChans)\n",
    "# AnalysisChans_int = np.array(AnalysisChans, dtype = int)\n",
    "# VisChans = np.sort(AnalysisChans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Bool mask for mne topoplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OcciMask = np.zeros((128), dtype = bool) # mask of len nchans\n",
    "# OcciMask[VisChans] = True # set good chans to true \n",
    "# #print(OcciMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save signal data\n",
    "# FreqDataPerCo = {}\n",
    "# for co in range(ExpConds):\n",
    "#     #print(MainData[co][0].shape)\n",
    "#     FreqDataPerCo[co] = MainData[co][0]\n",
    "# # noise data 1 \n",
    "# Noise1DataPerCo = {}\n",
    "# for co in range(ExpConds):\n",
    "#     #print(noise1[co][0].shape)\n",
    "#     Noise1DataPerCo[co] = noise1[co][0]\n",
    "# # noise data 2\n",
    "# Noise2DataPerCo = {}\n",
    "# for co in range(ExpConds):\n",
    "#     #print(noise2[co][0].shape)\n",
    "#     Noise2DataPerCo[co] = noise2[co][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co = 0 # pre and post induction ltp\n",
    "# HarmInd = np.ravel(mat_data['info'][0][0] [0][co][0])\n",
    "# BinInd = np.ravel(mat_data['info'][0][0] [1][co][0])\n",
    "# #HarmonLabels = mat_data['info'][0][0][2][co][0]\n",
    "# AvgAct = mat_data['info'][0][0] [3][co] [0] # returns an array with 6 values ...\n",
    "# NumCondInd = mat_data['info'][0][0][4][co][0] # bin index, includes preludes\n",
    "# HemiFieldLabels = mat_data['info'][0][0] [2][co][0] # contains harmonic and hemifield data\n",
    "# hemiFieldnHarmonicInd = mat_data['info'][0][0] [2][co] [0]\n",
    "#########IN case some nexted arrays need to be extracted or explored\n",
    "# co = 0\n",
    "# ind = 2\n",
    "# inds = mat_data['info'][0][0] [ind][co] [0] # avoid prelude bind which == 0 actually \n",
    "# #print(inds)\n",
    "# for innerlist in inds:\n",
    "#     for item in innerlist:\n",
    "#        print(item)\n",
    "# HemiBound = int(int(len(HemiFieldLabels))/2)\n",
    "# print(HemiBound) # index for Fx filter freq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
